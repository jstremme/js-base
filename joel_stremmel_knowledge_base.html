<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Joel Stremmel — Knowledge Base</title>
<style>
  :root {
    --bg: #0f1117;
    --surface: #1a1d27;
    --surface2: #232733;
    --border: #2e3343;
    --text: #e1e4ed;
    --text2: #8b90a0;
    --accent: #6c8cff;
    --accent2: #4a6adf;
    --paper: #e8a44a;
    --repo: #7ee787;
    --blog: #d2a8ff;
    --video: #ff7b72;
    --tool: #79c0ff;
    --podcast: #ffa657;
    --doc: #56d4dd;
    --news: #f778ba;
    --other: #8b949e;
    --pending: #ffd700;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }

  body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
    background: var(--bg);
    color: var(--text);
    line-height: 1.5;
    min-height: 100vh;
  }

  .header {
    position: sticky;
    top: 0;
    z-index: 100;
    background: var(--bg);
    border-bottom: 1px solid var(--border);
    padding: 16px 24px;
  }

  .header-inner {
    max-width: 960px;
    margin: 0 auto;
  }

  .header h1 {
    font-size: 18px;
    font-weight: 600;
    margin-bottom: 12px;
    color: var(--text);
  }
  .header h1 span { color: var(--text2); font-weight: 400; }

  .controls {
    display: flex;
    gap: 10px;
    align-items: center;
    flex-wrap: wrap;
  }

  #search {
    flex: 1;
    min-width: 200px;
    padding: 8px 12px;
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 6px;
    color: var(--text);
    font-size: 14px;
    outline: none;
    transition: border-color 0.15s;
  }
  #search:focus { border-color: var(--accent); }
  #search::placeholder { color: var(--text2); }

  .filter-bar {
    display: flex;
    gap: 6px;
    flex-wrap: wrap;
  }

  .filter-btn {
    padding: 4px 10px;
    font-size: 12px;
    border-radius: 12px;
    border: 1px solid var(--border);
    background: transparent;
    color: var(--text2);
    cursor: pointer;
    transition: all 0.15s;
  }
  .filter-btn:hover { border-color: var(--accent); color: var(--text); }
  .filter-btn.active { background: var(--accent2); border-color: var(--accent); color: #fff; }

  .stats {
    font-size: 12px;
    color: var(--text2);
    padding: 2px 0;
    white-space: nowrap;
  }

  .legend {
    display: flex;
    gap: 16px;
    align-items: center;
    font-size: 11px;
    color: var(--text2);
    margin-top: 8px;
  }
  .legend-item { display: flex; align-items: center; gap: 4px; }
  .legend-dot {
    display: inline-block;
    width: 8px;
    height: 8px;
    border-radius: 50%;
  }
  .legend-dot.filled { background: var(--accent); }
  .legend-dot.empty { border: 1.5px solid var(--text2); }
  .legend-dot.pending-dot { background: var(--pending); }

  /* --- Add Bookmark Panel --- */
  .bookmark-toggle {
    display: inline-flex;
    align-items: center;
    gap: 4px;
    padding: 4px 10px;
    font-size: 12px;
    border-radius: 12px;
    border: 1px solid var(--border);
    background: transparent;
    color: var(--text2);
    cursor: pointer;
    transition: all 0.15s;
  }
  .bookmark-toggle:hover { border-color: var(--accent); color: var(--text); }
  .bookmark-toggle.active { background: var(--accent2); border-color: var(--accent); color: #fff; }

  .bookmark-panel {
    display: none;
    max-width: 960px;
    margin: 0 auto;
    padding: 16px 24px;
    border-bottom: 1px solid var(--border);
  }
  .bookmark-panel.open { display: block; }

  .bookmark-panel .form-row {
    display: flex;
    gap: 10px;
    margin-bottom: 8px;
    align-items: center;
    flex-wrap: wrap;
  }

  .bookmark-panel input[type="text"],
  .bookmark-panel textarea,
  .bookmark-panel select {
    padding: 6px 10px;
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 6px;
    color: var(--text);
    font-size: 13px;
    outline: none;
    font-family: inherit;
  }
  .bookmark-panel input[type="text"]:focus,
  .bookmark-panel textarea:focus,
  .bookmark-panel select:focus { border-color: var(--accent); }

  .bookmark-panel input[type="text"] { flex: 1; min-width: 200px; }
  .bookmark-panel textarea { flex: 1; min-width: 200px; height: 60px; resize: vertical; }
  .bookmark-panel select { min-width: 140px; }

  .bookmark-panel label {
    font-size: 12px;
    color: var(--text2);
    min-width: 70px;
  }

  .btn {
    padding: 6px 14px;
    font-size: 12px;
    border-radius: 6px;
    border: 1px solid var(--border);
    background: var(--surface);
    color: var(--text);
    cursor: pointer;
    transition: all 0.15s;
    font-family: inherit;
  }
  .btn:hover { border-color: var(--accent); color: var(--accent); }
  .btn-primary {
    background: var(--accent2);
    border-color: var(--accent);
    color: #fff;
  }
  .btn-primary:hover { background: var(--accent); }
  .bookmark-actions {
    display: flex;
    gap: 8px;
    margin-top: 4px;
  }

  /* --- Main content --- */
  .container {
    max-width: 960px;
    margin: 0 auto;
    padding: 16px 24px 80px;
  }

  .category {
    margin-bottom: 8px;
    border: 1px solid var(--border);
    border-radius: 8px;
    overflow: hidden;
  }
  .category.hidden { display: none; }

  .cat-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 10px 16px;
    background: var(--surface);
    cursor: pointer;
    user-select: none;
    transition: background 0.15s;
  }
  .cat-header:hover { background: var(--surface2); }

  .cat-title {
    font-size: 14px;
    font-weight: 600;
    display: flex;
    align-items: center;
    gap: 8px;
  }

  .cat-count {
    font-size: 11px;
    color: var(--text2);
    background: var(--surface2);
    padding: 2px 8px;
    border-radius: 10px;
  }

  .chevron {
    font-size: 12px;
    color: var(--text2);
    transition: transform 0.2s;
  }
  .category.open .chevron { transform: rotate(90deg); }

  .cat-items {
    display: none;
    border-top: 1px solid var(--border);
  }
  .category.open .cat-items { display: block; }

  .item-row {
    border-bottom: 1px solid var(--border);
    transition: background 0.1s;
  }
  .item-row:last-child { border-bottom: none; }
  .item-row:hover { background: var(--surface); }
  .item-row.hidden { display: none; }

  .item {
    display: flex;
    align-items: center;
    gap: 8px;
    padding: 7px 16px;
    cursor: pointer;
  }

  .enrichment-dot {
    width: 7px;
    height: 7px;
    border-radius: 50%;
    flex-shrink: 0;
  }
  .enrichment-dot.filled { background: var(--accent); }
  .enrichment-dot.empty { border: 1.5px solid var(--text2); }

  .type-badge {
    font-size: 10px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    padding: 1px 6px;
    border-radius: 3px;
    flex-shrink: 0;
    width: 52px;
    text-align: center;
  }

  .type-paper { background: rgba(232,164,74,0.15); color: var(--paper); }
  .type-repo { background: rgba(126,231,135,0.15); color: var(--repo); }
  .type-blog { background: rgba(210,168,255,0.15); color: var(--blog); }
  .type-video { background: rgba(255,123,114,0.15); color: var(--video); }
  .type-tool { background: rgba(121,192,255,0.15); color: var(--tool); }
  .type-podcast { background: rgba(255,166,87,0.15); color: var(--podcast); }
  .type-documentation { background: rgba(86,212,221,0.15); color: var(--doc); width: 62px; }
  .type-news { background: rgba(247,120,186,0.15); color: var(--news); }
  .type-other { background: rgba(139,148,158,0.15); color: var(--other); }

  .item-link {
    color: var(--text);
    text-decoration: none;
    font-size: 13px;
    line-height: 1.4;
    flex: 1;
    overflow: hidden;
    text-overflow: ellipsis;
  }
  .item-link:hover { color: var(--accent); }

  .date-badge {
    font-size: 10px;
    color: var(--text2);
    background: var(--surface2);
    padding: 1px 6px;
    border-radius: 3px;
    flex-shrink: 0;
    white-space: nowrap;
  }

  .authors-inline {
    font-size: 11px;
    color: var(--text2);
    flex-shrink: 0;
    max-width: 180px;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }

  .item-domain {
    font-size: 11px;
    color: var(--text2);
    flex-shrink: 0;
    max-width: 120px;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }

  .pending-badge {
    font-size: 9px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    padding: 1px 5px;
    border-radius: 3px;
    background: rgba(255,215,0,0.15);
    color: var(--pending);
    flex-shrink: 0;
  }

  .item-detail {
    display: none;
    padding: 6px 16px 10px 38px;
    font-size: 12px;
    color: var(--text2);
    line-height: 1.5;
    border-top: 1px dashed var(--border);
  }
  .item-row.expanded .item-detail { display: block; }
  .item-detail .detail-summary { margin-bottom: 4px; }
  .item-detail .detail-authors { font-style: italic; }

  .no-results {
    text-align: center;
    padding: 60px 20px;
    color: var(--text2);
    font-size: 14px;
    display: none;
  }

  .keyboard-hint {
    font-size: 11px;
    color: var(--text2);
    padding: 2px 0;
  }
  kbd {
    background: var(--surface2);
    border: 1px solid var(--border);
    border-radius: 3px;
    padding: 0 4px;
    font-size: 11px;
    font-family: inherit;
  }

  @media (max-width: 640px) {
    .header { padding: 12px 16px; }
    .container { padding: 12px 16px 60px; }
    .item { padding: 6px 12px; }
    .item-domain, .authors-inline { display: none; }
    .controls { flex-direction: column; align-items: stretch; }
    .bookmark-panel { padding: 12px 16px; }
    .bookmark-panel .form-row { flex-direction: column; }
  }
</style>
</head>
<body>

<div class="header">
  <div class="header-inner">
    <h1>Joel Stremmel <span>— Knowledge Base</span></h1>
    <div class="controls">
      <input type="text" id="search" placeholder="Search titles, summaries, authors, URLs..." autofocus>
      <div class="filter-bar" id="filters"></div>
      <button class="bookmark-toggle" id="bookmark-toggle">+ Add Bookmark</button>
      <span class="stats" id="stats"></span>
    </div>
    <div class="legend" id="legend">
      <span class="legend-item"><span class="legend-dot filled"></span> enriched paper metadata</span>
      <span class="legend-item"><span class="legend-dot empty"></span> catalogued only</span>
    </div>
    <div class="keyboard-hint" style="margin-top:6px">
      <kbd>/</kbd> focus search &nbsp; <kbd>Esc</kbd> clear &nbsp; <kbd>E</kbd> expand all &nbsp; <kbd>C</kbd> collapse all
    </div>
  </div>
</div>

<div class="bookmark-panel" id="bookmark-panel">
  <div class="form-row">
    <label>URL</label>
    <input type="text" id="bm-url" placeholder="https://...">
  </div>
  <div class="form-row">
    <label>Title</label>
    <input type="text" id="bm-title" placeholder="Title (auto-populated if possible)">
  </div>
  <div class="form-row">
    <label>Category</label>
    <select id="bm-category"></select>
    <label>Type</label>
    <select id="bm-type">
      <option value="paper">paper</option>
      <option value="repo">repo</option>
      <option value="blog">blog</option>
      <option value="video">video</option>
      <option value="tool">tool</option>
      <option value="podcast">podcast</option>
      <option value="documentation">documentation</option>
      <option value="news">news</option>
      <option value="other" selected>other</option>
    </select>
  </div>
  <div class="form-row">
    <label>Summary</label>
    <textarea id="bm-summary" placeholder="Optional summary (2-3 sentences)"></textarea>
  </div>
  <div class="bookmark-actions">
    <button class="btn btn-primary" id="bm-add">Add Bookmark</button>
    <button class="btn" id="bm-export">Export JSON</button>
    <span id="bm-pending-count" style="font-size:12px;color:var(--text2)"></span>
  </div>
</div>

<div class="container" id="container">
  <div class="no-results" id="no-results">No matching items.</div>
</div>

<script>
const DATA = {"metadata": {"owner": "Joel Stremmel", "created": "2026-02-11", "sources": ["joel_stremmel_bookmarks.html", "bookmarks_2_11_26.html"], "total_items": 370, "total_categories": 22}, "categories": [{"name": "Prompt Engineering, Optimization, and Red-Teaming", "items": [{"title": "Query-Based Adversarial Prompt Generation", "url": "https://arxiv.org/abs/2402.12329", "source": "curated", "type": "paper", "summary": "Recent work has shown it is possible to construct adversarial examples that cause an aligned language model to emit harmful strings or perform harmful behavior. Existing attacks work either in the white-box setting (with full access to the model weights), or through transferability: the phenomenon that adversarial examples crafted on one model often remain effective on other models. We improve on prior work with a query-based attack that leverages API access to a remote language model to construct adversarial examples that cause the model to emit harmful strings with (much) higher probability than with transfer-only attacks.", "date": "2024-02-19", "authors": ["Jonathan Hayase", "Ema Borevkovic", "Nicholas Carlini", "Florian Tramèr", "Milad Nasr"]}, {"title": "Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts", "url": "https://arxiv.org/abs/2402.16822", "source": "curated", "type": "paper", "summary": "As large language models (LLMs) become increasingly prevalent across many real-world applications, understanding and enhancing their robustness to adversarial attacks is of paramount importance. Existing methods for identifying adversarial prompts tend to focus on specific domains, lack diversity, or require extensive human annotations. To address these limitations, we present Rainbow Teaming, a novel black-box approach for producing a diverse collection of adversarial prompts.", "date": "2024-02-26", "authors": ["Mikayel Samvelyan", "Sharath Chandra Raparthy", "Andrei Lupu", "Eric Hambro", "Aram H. Markosyan", "Manish Bhatt", "Yuning Mao", "Minqi Jiang", "Jack Parker-Holder", "Jakob Foerster", "Tim Rocktäschel", "Roberta Raileanu"]}, {"title": "AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs", "url": "https://arxiv.org/abs/2404.16873", "source": "curated", "type": "paper", "summary": "Large Language Models (LLMs) are vulnerable to jailbreaking attacks that lead to generation of inappropriate or harmful content. Manual red-teaming requires a time-consuming search for adversarial prompts, whereas automatic adversarial prompt generation often leads to semantically meaningless attacks that do not scale well. In this paper, we present a novel method that uses another LLM, called AdvPrompter, to generate human-readable adversarial prompts in seconds.", "date": "2024-04-21", "authors": ["Anselm Paulus", "Arman Zharmagambetov", "Chuan Guo", "Brandon Amos", "Yuandong Tian"]}, {"title": "CriSPO: Multi-Aspect Critique-Suggestion-guided Automatic Prompt Optimization for Text Generation", "url": "https://arxiv.org/abs/2410.02748", "type": "paper", "source": "chrome", "summary": "Existing automatic prompt engineering methods are typically designed for discriminative tasks, where new task prompts are iteratively refined with limited feedback from a single metric reflecting a single aspect. However, these approaches are suboptimal for generative tasks, which require more nuanced guidance beyond a single numeric metric to improve the prompt and optimize multiple aspects of the generated text. To address these challenges, we propose a novel multi-aspect Critique-Suggestion-guided automatic Prompt Optimization (CriSPO) approach.", "date": "2024-10-03", "authors": ["Han He", "Qianchu Liu", "Lei Xu", "Chaitanya Shivade", "Yi Zhang", "Sundararajan Srinivasan", "Katrin Kirchhoff"]}, {"title": "Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery", "url": "https://arxiv.org/abs/2302.03668", "type": "paper", "source": "chrome", "summary": "The strength of modern generative models lies in their ability to be controlled through text-based prompts. Typical \"hard\" prompts are made from interpretable words and tokens, and must be hand-crafted by humans. There are also \"soft\" prompts, which consist of continuous feature vectors.", "date": "2023-02-07", "authors": ["Yuxin Wen", "Neel Jain", "John Kirchenbauer", "Micah Goldblum", "Jonas Geiping", "Tom Goldstein"]}, {"title": "[2101.00190] Prefix-Tuning: Optimizing Continuous Prompts for Generation", "url": "https://arxiv.org/abs/2101.00190", "type": "paper", "source": "chrome", "summary": "Fine-tuning is the de facto way to leverage large pretrained language models to perform downstream tasks. However, it modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen, but optimizes a small continuous task-specific vector (called the prefix).", "date": "2021-01-01", "authors": ["Xiang Lisa Li", "Percy Liang"]}]}, {"name": "Automatically Evaluating Text Generation Systems", "items": [{"title": "G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment", "url": "https://arxiv.org/abs/2303.16634", "source": "both", "type": "paper", "summary": "The quality of texts generated by natural language generation (NLG) systems is hard to measure automatically. Conventional reference-based metrics, such as BLEU and ROUGE, have been shown to have relatively low correlation with human judgments, especially for tasks that require creativity and diversity. Recent studies suggest using large language models (LLMs) as reference-free metrics for NLG evaluation, which have the benefit of being applicable to new tasks that lack human references.", "date": "2023-03-29", "authors": ["Yang Liu", "Dan Iter", "Yichong Xu", "Shuohang Wang", "Ruochen Xu", "Chenguang Zhu"]}, {"title": "RAGAs: Automated Evaluation of Retrieval Augmented Generation", "url": "https://arxiv.org/abs/2309.15217", "source": "curated", "type": "paper", "summary": "We introduce Ragas (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. RAG systems are composed of a retrieval and an LLM based generation module, and provide LLMs with knowledge from a reference textual database, which enables them to act as a natural language layer between a user and textual databases, reducing the risk of hallucinations. Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself.", "date": "2023-09-26", "authors": ["Shahul Es", "Jithin James", "Luis Espinosa-Anke", "Steven Schockaert"]}, {"title": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems", "url": "https://arxiv.org/abs/2311.09476", "source": "curated", "type": "paper", "summary": "Evaluating retrieval-augmented generation (RAG) systems traditionally relies on hand annotations for input queries, passages to retrieve, and responses to generate. We introduce ARES, an Automated RAG Evaluation System, for evaluating RAG systems along the dimensions of context relevance, answer faithfulness, and answer relevance. By creating its own synthetic training data, ARES finetunes lightweight LM judges to assess the quality of individual RAG components.", "date": "2023-11-16", "authors": ["Jon Saad-Falcon", "Omar Khattab", "Christopher Potts", "Matei Zaharia"]}, {"title": "RAGChecker: A Fine-grained Framework for Diagnosing Retrieval-Augmented Generation", "url": "https://arxiv.org/abs/2408.08067", "source": "curated", "type": "paper", "summary": "Despite Retrieval-Augmented Generation (RAG) showing promising capability in leveraging external knowledge, a comprehensive evaluation of RAG systems is still challenging due to the modular nature of RAG, evaluation of long-form responses and reliability of measurements. In this paper, we propose a fine-grained evaluation framework, RAGChecker, that incorporates a suite of diagnostic metrics for both the retrieval and generation modules. Meta evaluation verifies that RAGChecker has significantly better correlations with human judgments than other evaluation metrics.", "date": "2024-08-15", "authors": ["Dongyu Ru", "Lin Qiu", "Xiangkun Hu", "Tianhang Zhang", "Peng Shi", "Shuaichen Chang", "Cheng Jiayang", "Cunxiang Wang", "Shichao Sun", "Huanyu Li", "Zizhao Zhang", "Binjie Wang", "Jiarong Jiang", "Tong He", "Zhiguo Wang", "Pengfei Liu", "Yue Zhang", "Zheng Zhang"]}, {"title": "Re-evaluating Automatic Summarization with BLEU and 192 Shades of ROUGE", "url": "https://aclanthology.org/D15-1013/", "source": "curated", "type": "paper", "date": "2015-01-01", "summary": null, "authors": null}, {"title": "The limits of automatic summarisation according to ROUGE", "url": "https://aclanthology.org/E17-2007/", "source": "curated", "type": "paper", "date": "2017-01-01", "summary": "This paper discusses some central caveats of summarisation, incurred in the use of the ROUGE metric for evaluation, with respect to optimal solutions. The task is NP-hard, of which we give the first proof. Still, as we show empirically for three central benchmark datasets for the task, greedy algorithms empirically seem to perform optimally according to the metric.", "authors": null}, {"title": "GitHub - huggingface/evaluation-guidebook: Sharing both practical insights and theoretical knowledge about LLM evaluation that we gathered while managing the Open LLM Leaderboard and designing lighteval!", "url": "https://github.com/huggingface/evaluation-guidebook", "source": "curated", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "Measuring the Groundedness of Legal Question-Answering Systems", "url": "https://arxiv.org/pdf/2410.08764", "source": "curated", "type": "paper", "summary": "In high-stakes domains like legal question-answering, the accuracy and trustworthiness of generative AI systems are of paramount importance. This work presents a comprehensive benchmark of various methods to assess the groundedness of AI-generated responses, aiming to significantly enhance their reliability. Our experiments include similarity-based metrics and natural language inference models to evaluate whether responses are well-founded in the given contexts.", "date": "2024-10-11", "authors": ["Dietrich Trautmann", "Natalia Ostapuk", "Quentin Grail", "Adrian Alan Pol", "Guglielmo Bonifazi", "Shang Gao", "Martin Gajek"]}, {"title": "STORYSUMM: Evaluating Faithfulness in Story Summarization", "url": "https://aclanthology.org/2024.emnlp-main.557/", "source": "curated", "type": "paper", "date": "2024-01-01", "summary": "Human evaluation has been the gold standard for checking faithfulness in abstractive summarization. However, with a challenging source domain like narrative, multiple annotators can agree a summary is faithful, while missing details that are obvious errors only once pointed out. We therefore introduce a new dataset, StorySumm, comprising LLM summaries of short stories with localized faithfulness labels and error explanations.", "authors": null}, {"title": "Towards an Automated Pointwise Evaluation Metric for Generated Long-Form Legal Summaries", "url": "https://aclanthology.org/2024.nllp-1.10/", "source": "both", "type": "paper", "date": "2024-01-01", "summary": "Long-form abstractive summarization is a task that has particular importance in the legal domain. Automated evaluation metrics are important for the development of text generation models, but existing research on the evaluation of generated summaries has focused mainly on short summaries. We introduce an automated evaluation methodology for generated long-form legal summaries, which involves breaking each summary into individual points, comparing the points in a human-written and machine-generated summary, and calculating a recall and precision score for the latter.", "authors": null}, {"title": "FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets", "url": "https://arxiv.org/abs/2307.10928", "source": "both", "type": "paper", "summary": "Evaluation of Large Language Models (LLMs) is challenging because instruction-following necessitates alignment with human values and the required set of skills varies depending on the instruction. However, previous studies have mainly focused on coarse-grained evaluation (i.e. overall preference-based evaluation), which limits interpretability since it does not consider the nature of user instructions that require instance-wise skill composition.", "date": "2023-07-20", "authors": ["Seonghyeon Ye", "Doyoung Kim", "Sungdong Kim", "Hyeonbin Hwang", "Seungone Kim", "Yongrae Jo", "James Thorne", "Juho Kim", "Minjoon Seo"]}, {"title": "Long-form factuality in large language models", "url": "https://arxiv.org/pdf/2403.18802", "source": "curated", "type": "paper", "summary": "Large language models (LLMs) often generate content that contains factual errors when responding to fact-seeking prompts on open-ended topics. To benchmark a model's long-form factuality in open domains, we first use GPT-4 to generate LongFact, a prompt set comprising thousands of questions spanning 38 topics. We then propose that LLM agents can be used as automated evaluators for long-form factuality through a method which we call Search-Augmented Factuality Evaluator (SAFE).", "date": "2024-03-27", "authors": ["Jerry Wei", "Chengrun Yang", "Xinying Song", "Yifeng Lu", "Nathan Hu", "Jie Huang", "Dustin Tran", "Daiyi Peng", "Ruibo Liu", "Da Huang", "Cosmo Du", "Quoc V. Le"]}, {"title": "An LLM‑as‑Judge Won't Save The Product—Fixing Your Process Will", "url": "https://eugeneyan.com/writing/eval-process/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[2503.19092] Rankers, Judges, and Assistants: Towards Understanding the Interplay of LLMs in Information Retrieval Evaluation", "url": "https://arxiv.org/abs/2503.19092", "type": "paper", "source": "chrome", "summary": "Large language models (LLMs) are increasingly integral to information retrieval (IR), powering ranking, evaluation, and AI-assisted content creation. This widespread adoption necessitates a critical examination of potential biases arising from the interplay between these LLM-based components. This paper synthesizes existing research and presents novel experiment designs that explore how LLM-based rankers and assistants influence LLM-based judges.", "date": "2025-03-24", "authors": ["Krisztian Balog", "Donald Metzler", "Zhen Qin"]}, {"title": "[2412.09569] JuStRank: Benchmarking LLM Judges for System Ranking", "url": "https://arxiv.org/abs/2412.09569", "type": "paper", "source": "chrome", "summary": "Given the rapid progress of generative AI, there is a pressing need to systematically compare and choose between the numerous models and configurations available. The scale and versatility of such evaluations make the use of LLM-based judges a compelling solution for this challenge. Crucially, this approach requires first to validate the quality of the LLM judge itself.", "date": "2024-12-12", "authors": ["Ariel Gera", "Odellia Boni", "Yotam Perlitz", "Roy Bar-Haim", "Lilach Eden", "Asaf Yehudai"]}, {"title": "[2509.15739] Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics", "url": "https://arxiv.org/abs/2509.15739", "type": "paper", "source": "chrome", "summary": "Large Language Models (LLMs) excel at linear reasoning tasks but remain underexplored on non-linear structures such as those found in natural debates, which are best expressed as argument graphs. We evaluate whether LLMs can approximate structured reasoning from Computational Argumentation Theory (CAT). Specifically, we use Quantitative Argumentation Debate (QuAD) semantics, which assigns acceptability scores to arguments based on their attack and support relations.", "date": "2025-09-19", "authors": ["Reza Sanayei", "Srdjan Vesic", "Eduardo Blanco", "Mihai Surdeanu"]}]}, {"name": "Food, Recipes, and Nutrition", "items": [{"title": "Chicken and Steak Fajitas on the Blackstone Griddle", "url": "https://www.youtube.com/watch?v=QuRe4k8rXxk", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "Beer Battered Halibut - Blackstone Products", "url": "https://blackstoneproducts.com/blogs/recipes/beer-battered-halibut?srsltid=AfmBOoqu_O7y07jLDsqqPmqw6kFC7Ecz5QZVhGePLYAQWyKYkr0G81zR", "source": "curated", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Calories, carbs or fats: Which is worse for my health? - Vital Record", "url": "https://vitalrecord.tamu.edu/calories-carbs-or-fats-which-is-worse-for-my-health/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Wine-tasting: it's junk science | Wine | The Guardian", "url": "https://www.theguardian.com/lifeandstyle/2013/jun/23/wine-tasting-junk-science-analysis", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Super Seedy Granola Bars | Minimalist Baker Recipes", "url": "https://minimalistbaker.com/super-seedy-granola-bars/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Exploring the Cuisine & Catacombs of Les Halles | Anthony Bourdain: No Reservations | Travel Channel - YouTube", "url": "https://www.youtube.com/watch?v=BH6XNusKH7c", "type": "video", "source": "chrome", "summary": null, "date": null, "authors": null}]}, {"name": "Case Law and Legal Research for ML Scientists", "items": [{"title": "LibGuides: Case Finding and Advanced Searching Strategies: Home", "url": "https://guides.law.stanford.edu/cases", "source": "both", "type": "other", "summary": null, "date": null, "authors": null}, {"title": "Case law retrieval: problems, methods, challenges and evaluations in the last 20 years", "url": "https://arxiv.org/abs/2202.07209", "source": "curated", "type": "paper", "summary": "Case law retrieval is the retrieval of judicial decisions relevant to a legal question. Case law retrieval comprises a significant amount of a lawyer's time, and is important to ensure accurate advice and reduce workload. We survey methods for case law retrieval from the past 20 years and outline the problems and challenges facing evaluation of case law retrieval systems going forward.", "date": "2022-02-15", "authors": ["Daniel Locke", "Guido Zuccon"]}, {"title": "How to Read a Legal Opinion: A Guide for New Law Students", "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1160925", "source": "curated", "type": "paper", "date": null, "summary": null, "authors": null}, {"title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models", "url": "https://arxiv.org/abs/2308.11462", "source": "curated", "type": "paper", "summary": "The advent of large language models (LLMs) and their adoption by the legal community has given rise to the question: what types of legal reasoning can LLMs perform? To enable greater study of this question, we present LegalBench: a collaboratively constructed legal reasoning benchmark consisting of 162 tasks covering six different types of legal reasoning. LegalBench was built through an interdisciplinary process, in which we collected tasks designed and hand-crafted by legal professionals.", "date": "2023-08-20", "authors": ["Neel Guha", "Julian Nyarko", "Daniel E. Ho", "Christopher Ré", "Adam Chilton", "Aditya Narayana", "Alex Chohlas-Wood", "Austin Peters", "Brandon Waldon", "Daniel N. Rockmore", "Diego Zambrano", "Dmitry Talisman", "Enam Hoque", "Faiz Surani", "Frank Fagan", "Galit Sarfaty", "Gregory M. Dickinson", "Haggai Porat", "Jason Hegland", "Jessica Wu", "Joe Nudell", "Joel Niklaus", "John Nay", "Jonathan H. Choi", "Kevin Tobia", "Margaret Hagan", "Megan Ma", "Michael Livermore", "Nikon Rasumov-Rahe", "Nils Holzenberger", "Noam Kolt", "Peter Henderson", "Sean Rehaag", "Sharad Goel", "Shang Gao", "Spencer Williams", "Sunny Gandhi", "Tom Zur", "Varun Iyer", "Zehua Li"]}, {"title": "Legal Research", "url": "https://store.nolo.com/products/legal-research-lres.html", "source": "curated", "type": "other", "summary": null, "date": null, "authors": null}, {"title": "Hallucination-Free? Assessing the Reliability of Leading AI Legal Research Tools", "url": "https://arxiv.org/abs/2405.20362", "source": "curated", "type": "paper", "summary": "Legal practice has witnessed a sharp rise in products incorporating artificial intelligence (AI). Such tools are designed to assist with a wide range of core legal tasks, from search and summarization of caselaw to document drafting. But the large language models used in these tools are prone to \"hallucinate,\" or make up false information, making their use risky in high-stakes domains.", "date": "2024-05-30", "authors": ["Varun Magesh", "Faiz Surani", "Matthew Dahl", "Mirac Suzgun", "Christopher D. Manning", "Daniel E. Ho"]}, {"title": "Sources of Law in the United States", "url": "https://www.youtube.com/watch?v=y-rAjwNhp_8", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "The Slightly Newer 5 Hour Law School", "url": "https://web.archive.org/web/20080516111222/http:/members.aol.com/ronin48th/hope.htm", "source": "curated", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Legal research: 3-step how-to guide", "url": "https://legal.thomsonreuters.com/en/insights/articles/basics-of-legal-research-steps-to-follow", "source": "both", "type": "news", "summary": null, "date": null, "authors": null}, {"title": "ACL 2024 Keynote: Can LLMs Reason & Plan?", "url": "https://www.youtube.com/watch?v=0E9BbA0gO1A", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "How Harmful Are Errors in AI Research Results? - Thomson Reuters Institute", "url": "https://blogs.thomsonreuters.com/en-us/innovation/how-harmful-are-errors-in-ai-research-results/", "source": "both", "type": "news", "summary": null, "date": null, "authors": null}, {"title": "Measuring the Groundedness of Legal Question-Answering Systems", "url": "https://arxiv.org/abs/2410.08764", "source": "curated", "type": "paper", "summary": "In high-stakes domains like legal question-answering, the accuracy and trustworthiness of generative AI systems are of paramount importance. This work presents a comprehensive benchmark of various methods to assess the groundedness of AI-generated responses, aiming to significantly enhance their reliability. Our experiments include similarity-based metrics and natural language inference models to evaluate whether responses are well-founded in the given contexts.", "date": "2024-10-11", "authors": ["Dietrich Trautmann", "Natalia Ostapuk", "Quentin Grail", "Adrian Alan Pol", "Guglielmo Bonifazi", "Shang Gao", "Martin Gajek"]}, {"title": "Enhancing Legal Case Retrieval via Scaling High-quality Synthetic Query-Candidate Pairs", "url": "http://arxiv.org/pdf/2410.06581", "source": "curated", "type": "paper", "summary": "Legal case retrieval (LCR) aims to provide similar cases as references for a given fact description. This task is crucial for promoting consistent judgments in similar cases, effectively enhancing judicial fairness and improving work efficiency for judges. However, existing works face two main challenges for real-world applications: existing works mainly focus on case-to-case retrieval using lengthy queries, which does not match real-world scenarios; and the limited data scale, with current datasets containing only hundreds of queries, is insufficient to satisfy the training requirements of existing data-hungry neural models.", "date": "2024-10-09", "authors": ["Cheng Gao", "Chaojun Xiao", "Zhenghao Liu", "Huimin Chen", "Zhiyuan Liu", "Maosong Sun"]}, {"title": "Casetext CEO: Why Vertical LLM Agents Are The New $1 Billion SaaS Opportunities", "url": "https://www.youtube.com/watch?v=eBVi_sLaYsc", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "Find Laws, Legal Help, and Attorneys - FindLaw", "url": "https://www.findlaw.com/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "How to Read a Legal Opinion", "url": "https://law2.wlu.edu/library/documents/kerrhowtoreadopinion.pdf", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Thinking Like A Lawyer In The Age Of Generative AI: Cognitive Limits On AI Adoption Among Lawyers by Daniel Schwarcz, Debarati Das, Dongyeop Kang, Brett McDonnell :: SSRN", "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5260645", "type": "paper", "source": "chrome", "date": null, "summary": null, "authors": null}]}, {"name": "Film, TV, Comedy, and Entertainment", "items": [{"title": "Robin Williams Makes an Insane First Appearance | Carson Tonight Show", "url": "https://www.youtube.com/watch?v=9NHVn4QfjZQ", "source": "both", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "My Brilliant Friend (TV series) - Wikipedia", "url": "https://en.wikipedia.org/wiki/My_Brilliant_Friend_(TV_series)", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "This Movie Sucks: “American Beauty” – NOUVELLE VAGUE", "url": "https://nouvellevague391228525.wordpress.com/2018/10/25/this-movie-sucks-american-beauty/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "https://www.chanhassendt.com/Online/printer.asp?sToken=1%2C02afffb0%2C55d154ab%2CF2965727-68BE-4520-9AE3-8F7B8BA6558D%2CtKOP0f29Wb2ytlphToPesAdrWiA%3D", "url": "https://www.chanhassendt.com/Online/printer.asp?sToken=1%2C02afffb0%2C55d154ab%2CF2965727-68BE-4520-9AE3-8F7B8BA6558D%2CtKOP0f29Wb2ytlphToPesAdrWiA%3D", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Watching Myself Watch Woody Allen Films", "url": "https://www.google.com/amp/s/www.newyorker.com/culture/richard-brody/watching-myself-watch-woody-allen-films/amp", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}]}, {"name": "General NLP", "items": [{"title": "GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer", "url": "https://arxiv.org/abs/2311.08526", "source": "curated", "type": "paper", "summary": "Named Entity Recognition (NER) is essential in various Natural Language Processing (NLP) applications. Traditional NER models are effective but limited to a set of predefined entity types. In contrast, Large Language Models (LLMs) can extract arbitrary entities through natural language instructions, offering greater flexibility.", "date": "2023-11-14", "authors": ["Urchade Zaratiana", "Nadi Tomeh", "Pierre Holat", "Thierry Charnois"]}, {"title": "Untitled", "url": "https://www.kdnuggets.com/implement-named-entity-recognition-with-hugging-face-transformers", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Understanding LLM Embeddings for Regression", "url": "https://arxiv.org/abs/2411.14708", "source": "both", "type": "paper", "summary": "With the rise of large language models (LLMs) for flexibly processing information as strings, a natural application is regression, specifically by preprocessing string representations into LLM embeddings as downstream features for metric prediction. In this paper, we provide one of the first comprehensive investigations into embedding-based regression and demonstrate that LLM embeddings as features can be better for high-dimensional regression tasks than using traditional feature engineering. This regression performance can be explained in part due to LLM embeddings over numeric data inherently preserving Lipschitz continuity over the feature space.", "date": "2024-11-22", "authors": ["Eric Tang", "Bangding Yang", "Xingyou Song"]}, {"title": "Are Aligned Language Models “Adversarially Aligned”?", "url": "https://www.youtube.com/watch?v=uqOfC3KSZFc", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "What happens if you treat ordinal ratings as interval data? Human evaluations in NLP are even more under-powered than you think", "url": "https://aclanthology.org/2021.emnlp-main.703/", "source": "curated", "type": "paper", "date": "2021-01-01", "summary": "Previous work has shown that human evaluations in NLP are notoriously under-powered. Here, we argue that there are two common factors which make this problem even worse: NLP studies usually (a) treat ordinal data as interval data and (b) operate under high variance settings while the differences they are hoping to detect are often subtle. We demonstrate through simulation that ordinal mixed effects models are better able to detect small differences between models, especially in high variance settings common in evaluations of generated texts.", "authors": null}, {"title": "With Little Power Comes Great Responsibility", "url": "https://aclanthology.org/2020.emnlp-main.745/", "source": "curated", "type": "paper", "date": "2020-01-01", "summary": "Despite its importance to experimental design, statistical power (the probability that, given a real effect, an experiment will reject the null hypothesis) has largely been ignored by the NLP community. Underpowered experiments make it more difficult to discern the difference between statistical noise and meaningful model improvements, and increase the chances of exaggerated findings. By meta-analyzing a set of existing NLP papers and datasets, we characterize typical power for a variety of settings and conclude that underpowered experiments are common in the NLP literature.", "authors": null}, {"title": "Watch lectures from the best researchers.", "url": "https://underline.io/events/469/sessions/18847/lecture/110082-keynote-tom-griffiths", "source": "both", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "Finally, a Replacement for BERT: Introducing ModernBERT", "url": "https://huggingface.co/blog/modernbert", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Why Larger Language Models Do In-context Learning Differently?", "url": "https://arxiv.org/abs/2405.19592", "source": "both", "type": "paper", "summary": "Large language models (LLM) have emerged as a powerful tool for AI, with the key ability of in-context learning (ICL), where they can perform well on unseen tasks based on a brief series of task examples without necessitating any adjustments to the model parameters. One recent interesting mysterious observation is that models of different scales may have different ICL behaviors: larger models tend to be more sensitive to noise in the test context. This work studies this observation theoretically aiming to improve the understanding of LLM and ICL.", "date": "2024-05-30", "authors": ["Zhenmei Shi", "Junyi Wei", "Zhuoyan Xu", "Yingyu Liang"]}, {"title": "Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation", "url": "https://arxiv.org/abs/2302.09664", "source": "both", "type": "paper", "summary": "We introduce a method to measure uncertainty in large language models. For tasks like question answering, it is essential to know when we can trust the natural language outputs of foundation models. We show that measuring uncertainty in natural language is challenging because of \"semantic equivalence\" -- different sentences can mean the same thing.", "date": "2023-02-19", "authors": ["Lorenz Kuhn", "Yarin Gal", "Sebastian Farquhar"]}, {"title": "Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models", "url": "https://arxiv.org/pdf/2310.04406", "source": "curated", "type": "paper", "summary": "While language models (LMs) have shown potential across a range of decision-making tasks, their reliance on simple acting processes limits their broad deployment as autonomous agents. In this paper, we introduce Language Agent Tree Search (LATS) -- the first general framework that synergizes the capabilities of LMs in reasoning, acting, and planning. By leveraging the in-context learning ability of LMs, we integrate Monte Carlo Tree Search into LATS to enable LMs as agents, along with LM-powered value functions and self-reflections for proficient exploration and enhanced decision-making.", "date": "2023-10-06", "authors": ["Andy Zhou", "Kai Yan", "Michal Shlapentokh-Rothman", "Haohan Wang", "Yu-Xiong Wang"]}, {"title": "You could have designed state of the art positional encoding", "url": "https://huggingface.co/blog/designing-positional-encoding", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Unlocking the Power of GeGLU: Advanced Activation Functions in Deep Learning", "url": "https://medium.com/@juanc.olamendy/unlocking-the-power-of-geglu-advanced-activation-functions-in-deep-learning-444868d6d89c", "source": "curated", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "How to Train Long-Context Language Models (Effectively)", "url": "https://arxiv.org/abs/2410.02660", "source": "curated", "type": "paper", "summary": "We study continued training and supervised fine-tuning (SFT) of a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development -- instead of perplexity or simple needle-in-a-haystack (NIAH) tests, we use a broad set of long-context downstream tasks, and we evaluate models after SFT as this better reveals long-context abilities. Supported by our robust evaluations, we run thorough experiments to decide the data mix for continued pre-training, the instruction tuning dataset, and many other design choices such as position extrapolation.", "date": "2024-10-03", "authors": ["Tianyu Gao", "Alexander Wettig", "Howard Yen", "Danqi Chen"]}, {"title": "Data Design For Fine-Tuning LLM Long Context Windows", "url": "https://cobusgreyling.medium.com/data-design-for-fine-tuning-llm-long-context-windows-083861c8de8c", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs", "url": "https://arxiv.org/abs/2410.08020", "source": "both", "type": "paper", "summary": "Recent efforts in fine-tuning language models often rely on automatic data selection, commonly using Nearest Neighbors retrieval from large datasets. However, we theoretically show that this approach tends to select redundant data, limiting its effectiveness or even hurting performance. To address this, we introduce SIFT, a data selection algorithm designed to reduce uncertainty about the model's response given a prompt, which unifies ideas from retrieval and active learning.", "date": "2024-10-10", "authors": ["Jonas Hübotter", "Sascha Bongni", "Ido Hakimi", "Andreas Krause"]}, {"title": "Large Language Models for Data Annotation and Synthesis: A Survey", "url": "https://arxiv.org/abs/2402.13446", "source": "both", "type": "paper", "summary": "Data annotation and synthesis generally refers to the labeling or generating of raw data with relevant information, which could be used for improving the efficacy of machine learning models. The process, however, is labor-intensive and costly. The emergence of advanced Large Language Models (LLMs), exemplified by GPT-4, presents an unprecedented opportunity to automate the complicated process of data annotation and synthesis.", "date": "2024-02-21", "authors": ["Zhen Tan", "Dawei Li", "Song Wang", "Alimohammad Beigi", "Bohan Jiang", "Amrita Bhattacharjee", "Mansooreh Karami", "Jundong Li", "Lu Cheng", "Huan Liu"]}, {"title": "Transductive Active Learning: Theory and Applications", "url": "https://arxiv.org/abs/2402.15898", "source": "curated", "type": "paper", "summary": "We study a generalization of classical active learning to real-world settings with concrete prediction targets where sampling is restricted to an accessible region of the domain, while prediction targets may lie outside this region. We analyze a family of decision rules that sample adaptively to minimize uncertainty about prediction targets. We are the first to show, under general regularity assumptions, that such decision rules converge uniformly to the smallest possible uncertainty obtainable from the accessible data.", "date": "2024-02-13", "authors": ["Jonas Hübotter", "Bhavya Sukhija", "Lenart Treven", "Yarden As", "Andreas Krause"]}, {"title": "Scalable-Softmax Is Superior for Attention", "url": "https://arxiv.org/abs/2501.19399", "source": "curated", "type": "paper", "summary": "The maximum element of the vector output by the Softmax function approaches zero as the input vector size increases. Transformer-based language models rely on Softmax to compute attention scores, causing the attention distribution to flatten as the context size grows. This reduces the model's ability to prioritize key information effectively and potentially limits its length generalization.", "date": "2025-01-31", "authors": ["Ken M. Nakanishi"]}, {"title": "RoFormer: Enhanced Transformer with Rotary Position Embedding", "url": "https://arxiv.org/abs/2104.09864", "source": "curated", "type": "paper", "summary": "Position encoding recently has shown effective in the transformer architecture. It enables valuable supervision for dependency modeling between elements at different positions of the sequence. In this paper, we first investigate various methods to integrate positional information into the learning process of transformer-based language models.", "date": "2021-04-20", "authors": ["Jianlin Su", "Yu Lu", "Shengfeng Pan", "Ahmed Murtadha", "Bo Wen", "Yunfeng Liu"]}, {"title": "The Surprising Effectiveness of Test-Time Training for Few-Shot Learning", "url": "https://arxiv.org/abs/2411.07279", "source": "both", "type": "paper", "summary": "Language models (LMs) have shown impressive performance on tasks within their training distribution, but often struggle with structurally novel tasks even when given a small number of in-context task examples. We investigate the effectiveness of test-time training (TTT) -- temporarily updating model parameters during inference using a loss derived from input data -- as a mechanism for improving LMs' reasoning and few-shot learning capabilities. On the Abstraction and Reasoning Corpus (ARC), performing TTT with in-context examples yields up to $6\\times$ higher accuracy compared to fine-tuned baselines -- reaching $53.0\\%$ on the public validation set with an 8B-parameter LM and $61.9\\%$ when ensembled with program-synthesis methods, matching average human performance.", "date": "2024-11-11", "authors": ["Ekin Akyürek", "Mehul Damani", "Adam Zweiger", "Linlu Qiu", "Han Guo", "Jyothish Pari", "Yoon Kim", "Jacob Andreas"]}, {"title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters", "url": "https://arxiv.org/abs/2408.03314", "source": "curated", "type": "paper", "summary": "Enabling LLMs to improve their outputs by using more test-time computation is a critical step towards building generally self-improving agents that can operate on open-ended natural language. In this paper, we study the scaling of inference-time computation in LLMs, with a focus on answering the question: if an LLM is allowed to use a fixed but non-trivial amount of inference-time compute, how much can it improve its performance on a challenging prompt? Answering this question has implications not only on the achievable performance of LLMs, but also on the future of LLM pretraining and how one should tradeoff inference-time and pre-training compute.", "date": "2024-08-06", "authors": ["Charlie Snell", "Jaehoon Lee", "Kelvin Xu", "Aviral Kumar"]}, {"title": "Using logprobs | OpenAI Cookbook", "url": "https://cookbook.openai.com/examples/using_logprobs", "source": "both", "type": "documentation", "summary": null, "date": null, "authors": null}, {"title": "Label Supervised LLaMA Finetuning", "url": "https://arxiv.org/abs/2310.01208", "source": "curated", "type": "paper", "summary": "The recent success of Large Language Models (LLMs) has gained significant attention in both academia and industry. Substantial efforts have been made to enhance the zero- and few-shot generalization capabilities of open-source LLMs through finetuning. Currently, the prevailing approach is instruction-tuning, which trains LLMs to complete real-world tasks by generating responses guided by natural language instructions.", "date": "2023-10-02", "authors": ["Zongxi Li", "Xianming Li", "Yuzhang Liu", "Haoran Xie", "Jing Li", "Fu-lee Wang", "Qing Li", "Xiaoqin Zhong"]}, {"title": "[2104.08671] When Does Pretraining Help? Assessing Self-Supervised Learning for Law and the CaseHOLD Dataset", "url": "https://arxiv.org/abs/2104.08671", "type": "paper", "source": "chrome", "summary": "While self-supervised learning has made rapid advances in natural language processing, it remains unclear when researchers should engage in resource-intensive domain-specific pretraining (domain pretraining). The law, puzzlingly, has yielded few documented instances of substantial gains to domain pretraining in spite of the fact that legal language is widely seen to be unique. We hypothesize that these existing results stem from the fact that existing legal NLP tasks are too easy and fail to meet conditions for when domain pretraining can help.", "date": "2021-04-18", "authors": ["Lucia Zheng", "Neel Guha", "Brandon R. Anderson", "Peter Henderson", "Daniel E. Ho"]}, {"title": "Cheril311/LSLTransformerEncoder", "url": "https://github.com/Cheril311/LSLTransformerEncoder", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Entropixplained", "url": "https://southbridge-research.notion.site/Entropixplained-11e5fec70db18022b083d7d7b0e93505", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[2404.18185] Ranked List Truncation for Large Language Model-based Re-Ranking", "url": "https://arxiv.org/abs/2404.18185", "type": "paper", "source": "chrome", "summary": "We study ranked list truncation (RLT) from a novel \"retrieve-then-re-rank\" perspective, where we optimize re-ranking by truncating the retrieved list (i.e., trim re-ranking candidates). RLT is crucial for re-ranking as it can improve re-ranking efficiency by sending variable-length candidate lists to a re-ranker on a per-query basis. It also has the potential to improve re-ranking effectiveness.", "date": "2024-04-28", "authors": ["Chuan Meng", "Negar Arabzadeh", "Arian Askari", "Mohammad Aliannejadi", "Maarten de Rijke"]}, {"title": "[2501.00663] Titans: Learning to Memorize at Test Time", "url": "https://arxiv.org/abs/2501.00663", "type": "paper", "source": "chrome", "summary": "Over more than a decade there has been an extensive research effort on how to effectively utilize recurrent models and attention. While recurrent models aim to compress the data into a fixed-size memory (called hidden state), attention allows attending to the entire context window, capturing the direct dependencies of all tokens. This more accurate modeling of dependencies, however, comes with a quadratic cost, limiting the model to a fixed-length context.", "date": "2024-12-31", "authors": ["Ali Behrouz", "Peilin Zhong", "Vahab Mirrokni"]}, {"title": "Transduction (machine learning) - Wikipedia", "url": "https://en.wikipedia.org/wiki/Transduction_(machine_learning)", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[2409.17270] Proof of Thought : Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning", "url": "https://arxiv.org/abs/2409.17270", "type": "paper", "source": "chrome", "summary": "Large Language Models (LLMs) have revolutionized natural language processing, yet they struggle with inconsistent reasoning, particularly in novel domains and complex logical sequences. This research introduces Proof of Thought, a framework that enhances the reliability and transparency of LLM outputs. Our approach bridges LLM-generated ideas with formal logic verification, employing a custom interpreter to convert LLM outputs into First Order Logic constructs for theorem prover scrutiny.", "date": "2024-09-25", "authors": ["Debargha Ganguly", "Srinivasan Iyengar", "Vipin Chaudhary", "Shivkumar Kalyanaraman"]}, {"title": "State-of-the-art text embedding via the Gemini API - Google Developers Blog", "url": "https://developers.googleblog.com/en/gemini-embedding-text-model-now-available-gemini-api/", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "A Diner for David Lynch: Poems in Remembrance of a Master", "url": "https://newversereview.substack.com/p/a-diner-for-david-lynch-poems-in", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation", "url": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[2408.02442] Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models", "url": "https://arxiv.org/abs/2408.02442", "type": "paper", "source": "chrome", "summary": "Structured generation, the process of producing content in standardized formats like JSON and XML, is widely utilized in real-world applications to extract key output information from large language models (LLMs). This study investigates whether such constraints on generation space impact LLMs abilities, including reasoning and domain knowledge comprehension. Specifically, we evaluate LLMs performance when restricted to adhere to structured formats versus generating free-form responses across various common tasks.", "date": "2024-08-05", "authors": ["Zhi Rui Tam", "Cheng-Kuang Wu", "Yi-Lin Tsai", "Chieh-Yen Lin", "Hung-yi Lee", "Yun-Nung Chen"]}, {"title": "randallbalestriero.github.io", "url": "https://randallbalestriero.github.io/", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Self-supervised learning: The dark matter of intelligence", "url": "https://ai.meta.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "No, We Don't Have to Choose Batch Sizes As Powers Of 2", "url": "https://sebastianraschka.com/blog/2022/batch-size-2.html", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "castorini/rank_llm: RankLLM is a Python toolkit for reproducible information retrieval research using rerankers, with a focus on listwise reranking.", "url": "https://github.com/castorini/rank_llm", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models | Qwen", "url": "https://qwenlm.github.io/blog/qwen3-embedding/", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "The Big LLM Architecture Comparison", "url": "https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "An Overview of Late Interaction Retrieval Models: ColBERT, ColPali, and ColQwen | Weaviate", "url": "https://weaviate.io/blog/late-interaction-overview", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[2506.05176] Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models", "url": "https://arxiv.org/abs/2506.05176", "type": "paper", "source": "chrome", "summary": "In this work, we introduce the Qwen3 Embedding series, a significant advancement over its predecessor, the GTE-Qwen series, in text embedding and reranking capabilities, built upon the Qwen3 foundation models. Leveraging the Qwen3 LLMs' robust capabilities in multilingual text understanding and generation, our innovative multi-stage training pipeline combines large-scale unsupervised pre-training with supervised fine-tuning on high-quality datasets. Effective model merging strategies further ensure the robustness and adaptability of the Qwen3 Embedding series.", "date": "2025-06-05", "authors": ["Yanzhao Zhang", "Mingxin Li", "Dingkun Long", "Xin Zhang", "Huan Lin", "Baosong Yang", "Pengjun Xie", "An Yang", "Dayiheng Liu", "Junyang Lin", "Fei Huang", "Jingren Zhou"]}, {"title": "Deep researcher with test-time diffusion", "url": "https://research.google/blog/deep-researcher-with-test-time-diffusion/?utm_source=linkedin&utm_medium=social&utm_campaign=social_post&utm_content=gr-acct", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Ahead of AI | Sebastian Raschka, PhD | Substack", "url": "https://magazine.sebastianraschka.com/", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Zero-shot medical event prediction using a generative pretrained transformer on electronic health records | Journal of the American Medical Informatics Association | Oxford Academic", "url": "https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocaf160/8277596", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Hazy Research", "url": "https://hazyresearch.stanford.edu/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "NeurIPS 2025 Papers", "url": "https://jalammar.github.io/assets/neurips_2025.html?utm_source=substack&utm_medium=email", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[2505.12570] Batched Self-Consistency Improves LLM Relevance Assessment and Ranking", "url": "https://arxiv.org/abs/2505.12570", "type": "paper", "source": "chrome", "summary": "LLM query-passage relevance assessment is typically studied using a one-by-one pointwise (PW) strategy where each LLM call judges one passage at a time. However, this strategy requires as many LLM calls as there are passages while also preventing information sharing between passages. We thus hypothesize that batched PW methods, which evaluate multiple passages per LLM call, can improve not only efficiency but also judgment quality -- by enabling content from multiple passages to be seen jointly.", "date": "2025-05-18", "authors": ["Anton Korikov", "Pan Du", "Scott Sanner", "Navid Rekabsaz"]}, {"title": "LLMs are Better Than You Think: Label-Guided In-Context Learning for Named Entity Recognition - ACL Anthology", "url": "https://aclanthology.org/2025.emnlp-main.1441/", "type": "paper", "source": "chrome", "date": "2025-01-01", "summary": "In-context learning (ICL) enables large language models (LLMs) to perform new tasks using only a few demonstrations. In Named Entity Recognition (NER), demonstrations are typically selected based on semantic similarity to the test instance, ignoring training labels and resulting in suboptimal performance. We introduce DEER, a new method that leverages training labels through token-level statistics to improve ICL performance.", "authors": null}, {"title": "Can Question Generation Debias Question Answering Models? A Case Study on Question–Context Lexical Overlap - ACL Anthology", "url": "https://aclanthology.org/2021.mrqa-1.6/", "type": "paper", "source": "chrome", "date": "2021-01-01", "summary": "Question answering (QA) models for reading comprehension have been demonstrated to exploit unintended dataset biases such as question–context lexical overlap. This hinders QA models from generalizing to under-represented samples such as questions with low lexical overlap. Question generation (QG), a method for augmenting QA datasets, can be a solution for such performance degradation if QG can properly debias QA datasets.", "authors": null}, {"title": "Rank-Stabilized LoRA: Unlocking the Potential of LoRA Fine-Tuning", "url": "https://huggingface.co/blog/damjan-k/rslora", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "What Is SwiGLU? How to Implement It? And Why Does it Work?", "url": "https://azizbelaweid.substack.com/p/what-is-swiglu-how-to-implement-it", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[2507.11855] OrdShap: Feature Position Importance for Sequential Black-Box Models", "url": "https://arxiv.org/abs/2507.11855", "type": "paper", "source": "chrome", "summary": "Sequential deep learning models excel in domains with temporal or sequential dependencies, but their complexity necessitates post-hoc feature attribution methods for understanding their predictions. While existing techniques quantify feature importance, they inherently assume fixed feature ordering - conflating the effects of (1) feature values and (2) their positions within input sequences. To address this gap, we introduce OrdShap, a novel attribution method that disentangles these effects by quantifying how a model's predictions change in response to permuting feature position.", "date": "2025-07-16", "authors": ["Davin Hill", "Brian L. Hill", "Aria Masoomi", "Vijay S. Nori", "Robert E. Tillman", "Jennifer Dy"]}, {"title": "Understanding and Mitigating Numerical Sources of Nondeterminism in LLM Inference", "url": "https://openreview.net/pdf?id=Q3qAsZAEZw", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models - ACL Anthology", "url": "https://aclanthology.org/2024.emnlp-main.813/", "type": "paper", "source": "chrome", "date": "2024-01-01", "summary": "Retrieval-augmented language model (RALM) represents a significant advancement in mitigating factual hallucination by leveraging external knowledge sources. However, the reliability of the retrieved information is not always guaranteed, and the retrieval of irrelevant data can mislead the response generation. Moreover, standard RALMs frequently neglect their intrinsic knowledge due to the interference from retrieved information.", "authors": null}, {"title": "How Transformers Think: The Information Flow That Makes Language Models Work - KDnuggets", "url": "https://www.kdnuggets.com/how-transformers-think-the-information-flow-that-makes-language-models-work", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[2504.14858] Retrieval is Not Enough: Enhancing RAG Reasoning through Test-Time Critique and Optimization", "url": "https://arxiv.org/abs/2504.14858", "type": "paper", "source": "chrome", "summary": "Retrieval-augmented generation (RAG) has become a widely adopted paradigm for enabling knowledge-grounded large language models (LLMs). However, standard RAG pipelines often fail to ensure that model reasoning remains consistent with the evidence retrieved, leading to factual inconsistencies or unsupported conclusions. In this work, we reinterpret RAG as Retrieval-Augmented Reasoning and identify a central but underexplored problem: Reasoning Misalignment -- the divergence between an LLM's internal reasoning trajectory and the evidential constraints provided by retrieval.", "date": "2025-04-21", "authors": ["Jiaqi Wei", "Hao Zhou", "Xiang Zhang", "Di Zhang", "Zijie Qiu", "Wei Wei", "Jinzhe Li", "Wanli Ouyang", "Siqi Sun"]}, {"title": "Building a web search engine from scratch in two months with 3 billion neural embeddings", "url": "https://blog.wilsonl.in/search-engine/", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[2310.09497] A Setwise Approach for Effective and Highly Efficient Zero-shot Ranking with Large Language Models", "url": "https://arxiv.org/abs/2310.09497", "type": "paper", "source": "chrome", "summary": "We propose a novel zero-shot document ranking approach based on Large Language Models (LLMs): the Setwise prompting approach. Our approach complements existing prompting approaches for LLM-based zero-shot ranking: Pointwise, Pairwise, and Listwise. Through the first-of-its-kind comparative evaluation within a consistent experimental framework and considering factors like model size, token consumption, latency, among others, we show that existing approaches are inherently characterised by trade-offs between effectiveness and efficiency.", "date": "2023-10-14", "authors": ["Shengyao Zhuang", "Honglei Zhuang", "Bevan Koopman", "Guido Zuccon"]}, {"title": "Goodfire AI", "url": "https://www.goodfire.ai/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "When Attention Collapses: How Degenerate Layers in LLMs Enable Smaller, Stronger Models | OpenReview", "url": "https://openreview.net/forum?id=2zQn0bUoPf&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DTMLR%2FAuthors%23your-submissions)", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Gumini SLLM Report - a Hugging Face Space by GuminiResearch", "url": "https://huggingface.co/spaces/GuminiResearch/Gumini_sLLM_Report", "type": "tool", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[1707.01836] Cardiologist-Level Arrhythmia Detection with Convolutional Neural Networks", "url": "https://arxiv.org/abs/1707.01836", "type": "paper", "source": "chrome", "summary": "We develop an algorithm which exceeds the performance of board certified cardiologists in detecting a wide range of heart arrhythmias from electrocardiograms recorded with a single-lead wearable monitor. We build a dataset with more than 500 times the number of unique patients than previously studied corpora. On this dataset, we train a 34-layer convolutional neural network which maps a sequence of ECG samples to a sequence of rhythm classes.", "date": "2017-07-06", "authors": ["Pranav Rajpurkar", "Awni Y. Hannun", "Masoumeh Haghpanahi", "Codie Bourn", "Andrew Y. Ng"]}]}, {"name": "Information Retrieval Resources", "items": [{"title": "Passage Re-ranking with BERT", "url": "https://arxiv.org/abs/1901.04085", "source": "curated", "type": "paper", "summary": "Recently, neural models pretrained on a language modeling task, such as ELMo (Peters et al., 2017), OpenAI GPT (Radford et al., 2018), and BERT (Devlin et al., 2018), have achieved impressive results on various natural language processing tasks such as question-answering and natural language inference. In this paper, we describe a simple re-implementation of BERT for query-based passage re-ranking. Our system is the state of the art on the TREC-CAR dataset and the top entry in the leaderboard of the MS MARCO passage retrieval task, outperforming the previous state of the art by 27% (relative) in MRR@10.", "date": "2019-01-13", "authors": ["Rodrigo Nogueira", "Kyunghyun Cho"]}, {"title": "Dense Passage Retrieval for Open-Domain Question Answering", "url": "https://arxiv.org/abs/2004.04906", "source": "curated", "type": "paper", "summary": "Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system largely by 9%-19% absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks.", "date": "2020-04-10", "authors": ["Vladimir Karpukhin", "Barlas Oğuz", "Sewon Min", "Patrick Lewis", "Ledell Wu", "Sergey Edunov", "Danqi Chen", "Wen-tau Yih"]}, {"title": "Unsupervised Dense Information Retrieval with Contrastive Learning", "url": "https://arxiv.org/pdf/2112.09118", "source": "curated", "type": "paper", "summary": "Recently, information retrieval has seen the emergence of dense retrievers, using neural networks, as an alternative to classical sparse methods based on term-frequency. These models have obtained state-of-the-art results on datasets and tasks where large training sets are available. However, they do not transfer well to new applications with no training data, and are outperformed by unsupervised term-frequency methods such as BM25.", "date": "2021-12-16", "authors": ["Gautier Izacard", "Mathilde Caron", "Lucas Hosseini", "Sebastian Riedel", "Piotr Bojanowski", "Armand Joulin", "Edouard Grave"]}, {"title": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT", "url": "https://arxiv.org/abs/2004.12832", "source": "curated", "type": "paper", "summary": "Recent progress in Natural Language Understanding (NLU) is driving fast-paced advances in Information Retrieval (IR), largely owed to fine-tuning deep language models (LMs) for document ranking. While remarkably effective, the ranking models based on these LMs increase computational cost by orders of magnitude over prior approaches, particularly as they must feed each query-document pair through a massive neural network to compute a single relevance score. To tackle this, we present ColBERT, a novel ranking model that adapts deep LMs (in particular, BERT) for efficient retrieval.", "date": "2020-04-27", "authors": ["Omar Khattab", "Matei Zaharia"]}, {"title": "ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction", "url": "https://arxiv.org/abs/2112.01488", "source": "curated", "type": "paper", "summary": "Neural information retrieval (IR) has greatly advanced search and other knowledge-intensive language tasks. While many neural IR methods encode queries and documents into single-vector representations, late interaction models produce multi-vector representations at the granularity of each token and decompose relevance modeling into scalable token-level computations. This decomposition has been shown to make late interaction more effective, but it inflates the space footprint of these models by an order of magnitude.", "date": "2021-12-02", "authors": ["Keshav Santhanam", "Omar Khattab", "Jon Saad-Falcon", "Christopher Potts", "Matei Zaharia"]}, {"title": "Moving Beyond Downstream Task Accuracy for Information Retrieval Benchmarking", "url": "https://arxiv.org/abs/2212.01340", "source": "curated", "type": "paper", "summary": "Neural information retrieval (IR) systems have progressed rapidly in recent years, in large part due to the release of publicly available benchmarking tasks. Unfortunately, some dimensions of this progress are illusory: the majority of the popular IR benchmarks today focus exclusively on downstream task accuracy and thus conceal the costs incurred by systems that trade away efficiency for quality. Latency, hardware cost, and other efficiency considerations are paramount to the deployment of IR systems in user-facing settings.", "date": "2022-12-02", "authors": ["Keshav Santhanam", "Jon Saad-Falcon", "Martin Franz", "Omar Khattab", "Avirup Sil", "Radu Florian", "Md Arafat Sultan", "Salim Roukos", "Matei Zaharia", "Christopher Potts"]}, {"title": "A Survey on In-context Learning", "url": "https://arxiv.org/abs/2301.00234", "source": "curated", "type": "paper", "summary": "With the increasing capabilities of large language models (LLMs), in-context learning (ICL) has emerged as a new paradigm for natural language processing (NLP), where LLMs make predictions based on contexts augmented with a few examples. It has been a significant trend to explore ICL to evaluate and extrapolate the ability of LLMs. In this paper, we aim to survey and summarize the progress and challenges of ICL.", "date": "2022-12-31", "authors": ["Qingxiu Dong", "Lei Li", "Damai Dai", "Ce Zheng", "Jingyuan Ma", "Rui Li", "Heming Xia", "Jingjing Xu", "Zhiyong Wu", "Tianyu Liu", "Baobao Chang", "Xu Sun", "Lei Li", "Zhifang Sui"]}, {"title": "Two Tower Model Architecture: Current State and Promising Extensions", "url": "https://blog.reachsumit.com/posts/2023/03/two-tower-model/", "source": "curated", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Understanding and Coding the Self-Attention Mechanism of Large Language Models From Scratch", "url": "https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html", "source": "curated", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "GitHub - AnswerDotAI/RAGatouille: Easily use and train state of the art late-interaction retrieval methods (ColBERT) in any RAG pipeline. Designed for modularity and ease-of-use, backed by research.", "url": "https://github.com/AnswerDotAI/RAGatouille", "source": "curated", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "MIPRO and DSPy with Krista Opsahl-Ong! - Weaviate Podcast #103", "url": "https://open.spotify.com/episode/1LzHwVXBiHgoi3xu72RsgK?si=30f66fed53d04cb1", "source": "curated", "type": "podcast", "summary": null, "date": null, "authors": null}, {"title": "The Future of Search with Nils Reimers and Erika Cardenas - Weaviate Podcast #97!", "url": "https://open.spotify.com/episode/0OCGyGXzcXT2CK3FHwQvRc", "source": "curated", "type": "podcast", "summary": null, "date": null, "authors": null}, {"title": "A passage-based approach to learning to rank documents", "url": "https://link.springer.com/article/10.1007/s10791-020-09369-x", "source": "curated", "type": "paper", "date": null, "summary": null, "authors": null}, {"title": "Stanford CS25: V3 I Retrieval Augmented Language Models", "url": "https://www.youtube.com/watch?v=mE7IDf2SmJg", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "Retrieve & Re-Rank — Sentence Transformers  documentation", "url": "https://www.sbert.net/examples/applications/information-retrieval/README.html", "source": "curated", "type": "documentation", "summary": null, "date": null, "authors": null}, {"title": "Information Retrieval Resources", "url": "https://nlp.stanford.edu/IR-book/information-retrieval.html", "source": "curated", "type": "documentation", "summary": null, "date": null, "authors": null}, {"title": "In-context Learning with Retrieved Demonstrations for Language Models: A Survey", "url": "https://arxiv.org/abs/2401.11624", "source": "curated", "type": "paper", "summary": "Language models, especially pre-trained large language models, have showcased remarkable abilities as few-shot in-context learners (ICL), adept at adapting to new tasks with just a few demonstrations in the input context. However, the model's ability to perform ICL is sensitive to the choice of the few-shot demonstrations. Instead of using a fixed set of demonstrations, one recent development is to retrieve demonstrations tailored to each input query.", "date": "2024-01-21", "authors": ["Man Luo", "Xin Xu", "Yue Liu", "Panupong Pasupat", "Mehran Kazemi"]}, {"title": "Retrieval-Augmented Generation for Large Language Models: A Survey", "url": "https://arxiv.org/abs/2312.10997", "source": "curated", "type": "paper", "summary": "Large Language Models (LLMs) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information.", "date": "2023-12-18", "authors": ["Yunfan Gao", "Yun Xiong", "Xinyu Gao", "Kangxiang Jia", "Jinliu Pan", "Yuxi Bi", "Yi Dai", "Jiawei Sun", "Meng Wang", "Haofen Wang"]}, {"title": "Query Rewriting for Retrieval-Augmented Large Language Models", "url": "https://arxiv.org/abs/2305.14283", "source": "curated", "type": "paper", "summary": "Large Language Models (LLMs) play powerful, black-box readers in the retrieve-then-read pipeline, making remarkable progress in knowledge-intensive tasks. This work introduces a new framework, Rewrite-Retrieve-Read instead of the previous retrieve-then-read for the retrieval-augmented LLMs from the perspective of the query rewriting. Unlike prior studies focusing on adapting either the retriever or the reader, our approach pays attention to the adaptation of the search query itself, for there is inevitably a gap between the input text and the needed knowledge in retrieval.", "date": "2023-05-23", "authors": ["Xinbei Ma", "Yeyun Gong", "Pengcheng He", "Hai Zhao", "Nan Duan"]}, {"title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks", "url": "https://arxiv.org/abs/2005.11401", "source": "curated", "type": "paper", "summary": "Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems.", "date": "2020-05-22", "authors": ["Patrick Lewis", "Ethan Perez", "Aleksandra Piktus", "Fabio Petroni", "Vladimir Karpukhin", "Naman Goyal", "Heinrich Küttler", "Mike Lewis", "Wen-tau Yih", "Tim Rocktäschel", "Sebastian Riedel", "Douwe Kiela"]}, {"title": "Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval", "url": "https://arxiv.org/abs/2007.00808", "source": "curated", "type": "paper", "summary": "Conducting text retrieval in a dense learned representation space has many intriguing advantages over sparse retrieval. Yet the effectiveness of dense retrieval (DR) often requires combination with sparse retrieval. In this paper, we identify that the main bottleneck is in the training mechanisms, where the negative instances used in training are not representative of the irrelevant documents in testing.", "date": "2020-07-01", "authors": ["Lee Xiong", "Chenyan Xiong", "Ye Li", "Kwok-Fung Tang", "Jialin Liu", "Paul Bennett", "Junaid Ahmed", "Arnold Overwijk"]}, {"title": "Improving Efficient Neural Ranking Models with Cross-Architecture Knowledge Distillation", "url": "https://arxiv.org/abs/2010.02666", "source": "curated", "type": "paper", "summary": "Retrieval and ranking models are the backbone of many applications such as web search, open domain QA, or text-based recommender systems. The latency of neural ranking models at query time is largely dependent on the architecture and deliberate choices by their designers to trade-off effectiveness for higher efficiency. This focus on low query latency of a rising number of efficient ranking architectures make them feasible for production deployment.", "date": "2020-10-06", "authors": ["Sebastian Hofstätter", "Sophia Althammer", "Michael Schröder", "Mete Sertkan", "Allan Hanbury"]}, {"title": "MTEB Leaderboard - a Hugging Face Space by mteb", "url": "https://huggingface.co/spaces/mteb/leaderboard", "source": "both", "type": "tool", "summary": null, "date": null, "authors": null}, {"title": "Text Embeddings by Weakly-Supervised Contrastive Pre-training", "url": "https://arxiv.org/abs/2212.03533", "source": "curated", "type": "paper", "summary": "This paper presents E5, a family of state-of-the-art text embeddings that transfer well to a wide range of tasks. The model is trained in a contrastive manner with weak supervision signals from our curated large-scale text pair dataset (called CCPairs). E5 can be readily used as a general-purpose embedding model for any tasks requiring a single-vector representation of texts such as retrieval, clustering, and classification, achieving strong performance in both zero-shot and fine-tuned settings.", "date": "2022-12-07", "authors": ["Liang Wang", "Nan Yang", "Xiaolong Huang", "Binxing Jiao", "Linjun Yang", "Daxin Jiang", "Rangan Majumder", "Furu Wei"]}, {"title": "LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders", "url": "https://arxiv.org/abs/2404.05961", "source": "curated", "type": "paper", "summary": "Large decoder-only language models (LLMs) are the state-of-the-art models on most of today's NLP tasks and benchmarks. Yet, the community is only slowly adopting these models for text embedding tasks, which require rich contextualized representations. In this work, we introduce LLM2Vec, a simple unsupervised approach that can transform any decoder-only LLM into a strong text encoder.", "date": "2024-04-09", "authors": ["Parishad BehnamGhader", "Vaibhav Adlakha", "Marius Mosbach", "Dzmitry Bahdanau", "Nicolas Chapados", "Siva Reddy"]}, {"title": "Query Transformations", "url": "https://blog.langchain.dev/query-transformations/", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent", "url": "https://arxiv.org/abs/2304.09542", "source": "curated", "type": "paper", "summary": "Large Language Models (LLMs) have demonstrated remarkable zero-shot generalization across various language-related tasks, including search engines. However, existing work utilizes the generative ability of LLMs for Information Retrieval (IR) rather than direct passage ranking. The discrepancy between the pre-training objectives of LLMs and the ranking objective poses another challenge.", "date": "2023-04-19", "authors": ["Weiwei Sun", "Lingyong Yan", "Xinyu Ma", "Shuaiqiang Wang", "Pengjie Ren", "Zhumin Chen", "Dawei Yin", "Zhaochun Ren"]}, {"title": "Practical Learning-to-Rank: Deep, Fast, Precise - Roman Grebennikov", "url": "https://www.youtube.com/watch?v=oXfFqAKf4Ac", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "How LambdaMART works - optimizing product ranking goals", "url": "https://softwaredoug.com/blog/2021/11/28/how-lammbamart-works", "source": "curated", "type": "other", "summary": null, "date": null, "authors": null}, {"title": "LambdaMART in Depth", "url": "https://softwaredoug.com/blog/2022/01/17/lambdamart-in-depth", "source": "curated", "type": "other", "summary": null, "date": null, "authors": null}, {"title": "Beyond Yes and No: Improving Zero-Shot LLM Rankers via Scoring Fine-Grained Relevance Labels", "url": "https://arxiv.org/abs/2310.14122", "source": "curated", "type": "paper", "summary": "Zero-shot text rankers powered by recent LLMs achieve remarkable ranking performance by simply prompting. Existing prompts for pointwise LLM rankers mostly ask the model to choose from binary relevance labels like \"Yes\" and \"No\". However, the lack of intermediate relevance label options may cause the LLM to provide noisy or biased answers for documents that are partially relevant to the query.", "date": "2023-10-21", "authors": ["Honglei Zhuang", "Zhen Qin", "Kai Hui", "Junru Wu", "Le Yan", "Xuanhui Wang", "Michael Bendersky"]}, {"title": "Top-Down Partitioning for Efficient List-Wise Ranking", "url": "https://arxiv.org/abs/2405.14589", "source": "curated", "type": "paper", "summary": "Large Language Models (LLMs) have significantly impacted many facets of natural language processing and information retrieval. Unlike previous encoder-based approaches, the enlarged context window of these generative models allows for ranking multiple documents at once, commonly called list-wise ranking. However, there are still limits to the number of documents that can be ranked in a single inference of the model, leading to the broad adoption of a sliding window approach to identify the k most relevant items in a ranked list.", "date": "2024-05-23", "authors": ["Andrew Parry", "Sean MacAvaney", "Debasis Ganguly"]}, {"title": "Introducing Contextual Retrieval", "url": "https://www.anthropic.com/news/contextual-retrieval", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs", "url": "https://arxiv.org/abs/2406.11695", "source": "curated", "type": "paper", "summary": "Language Model Programs, i.e. sophisticated pipelines of modular language model (LM) calls, are increasingly advancing NLP tasks, but they require crafting prompts that are jointly effective for all modules. We study prompt optimization for LM programs, i.e.", "date": "2024-06-17", "authors": ["Krista Opsahl-Ong", "Michael J Ryan", "Josh Purtell", "David Broman", "Christopher Potts", "Matei Zaharia", "Omar Khattab"]}, {"title": "Evaluating the Ideal Chunk Size for a RAG System using LlamaIndex — LlamaIndex, Data Framework for LLM Applications", "url": "https://www.llamaindex.ai/blog/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5", "source": "both", "type": "documentation", "summary": null, "date": null, "authors": null}, {"title": "Contrastive Learning in PyTorch - Part 1: Introduction", "url": "https://www.youtube.com/watch?v=u-X_nZRsn5M", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "COCO-DR: Combating the Distribution Shift in Zero-Shot Dense Retrieval with Contrastive and Distributionally Robust Learning", "url": "https://arxiv.org/abs/2210.15212", "source": "curated", "type": "paper", "summary": "We present a new zero-shot dense retrieval (ZeroDR) method, COCO-DR, to improve the generalization ability of dense retrieval by combating the distribution shifts between source training tasks and target scenarios. To mitigate the impact of document differences, COCO-DR continues pretraining the language model on the target corpora to adapt the model to target distributions via COtinuous COtrastive learning. To prepare for unseen target queries, COCO-DR leverages implicit Distributionally Robust Optimization (iDRO) to reweight samples from different source query clusters for improving model robustness over rare queries during fine-tuning.", "date": "2022-10-27", "authors": ["Yue Yu", "Chenyan Xiong", "Si Sun", "Chao Zhang", "Arnold Overwijk"]}, {"title": "COIL: Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List", "url": "https://arxiv.org/pdf/2104.07186", "source": "curated", "type": "paper", "summary": "Classical information retrieval systems such as BM25 rely on exact lexical match and carry out search efficiently with inverted list index. Recent neural IR models shifts towards soft semantic matching all query document terms, but they lose the computation efficiency of exact match systems. This paper presents COIL, a contextualized exact match retrieval architecture that brings semantic lexical matching.", "date": "2021-04-15", "authors": ["Luyu Gao", "Zhuyun Dai", "Jamie Callan"]}, {"title": "ALR$^2$: A Retrieve-then-Reason Framework for Long-context Question Answering", "url": "https://arxiv.org/pdf/2410.03227", "source": "curated", "type": "paper", "summary": "The context window of large language models (LLMs) has been extended significantly in recent years. However, while the context length that the LLM can process has grown, the capability of the model to accurately reason over that context degrades noticeably. This occurs because modern LLMs often become overwhelmed by the vast amount of information in the context; when answering questions, the model must identify and reason over relevant evidence sparsely distributed throughout the text.", "date": "2024-10-04", "authors": ["Huayang Li", "Pat Verga", "Priyanka Sen", "Bowen Yang", "Vijay Viswanathan", "Patrick Lewis", "Taro Watanabe", "Yixuan Su"]}, {"title": "Contextual Document Embeddings", "url": "https://arxiv.org/abs/2410.02525", "source": "curated", "type": "paper", "summary": "Dense document embeddings are central to neural retrieval. The dominant paradigm is to train and construct embeddings by running encoders directly on individual documents. In this work, we argue that these embeddings, while effective, are implicitly out-of-context for targeted use cases of retrieval, and that a contextualized document embedding should take into account both the document and neighboring documents in context - analogous to contextualized word embeddings.", "date": "2024-10-03", "authors": ["John X. Morris", "Alexander M. Rush"]}, {"title": "Reciprocal Rank Fusion (RRF) explained in 4 mins.", "url": "https://medium.com/@devalshah1619/mathematical-intuition-behind-reciprocal-rank-fusion-rrf-explained-in-2-mins-002df0cc5e2a", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Astute RAG: Overcoming Imperfect Retrieval Augmentation and ...", "url": "https://arxiv.org/html/2410.07176v1", "source": "curated", "type": "paper", "date": "2024-10-09", "summary": "Retrieval augmented generation (RAG), while effectively integrating external knowledge to address the inherent limitations of large language models (LLMs), can be hindered by imperfect retrieval that contain irrelevant, misleading, or even malicious information. Previous studies have rarely connected the behavior of RAG through joint analysis, particularly regarding error propagation coming from imperfect retrieval and potential conflicts between LLMs' internal knowledge and external sources. Through comprehensive and controlled analyses under realistic conditions, we find that imperfect retrieval augmentation is inevitable, common, and harmful.", "authors": ["Fei Wang", "Xingchen Wan", "Ruoxi Sun", "Jiefeng Chen", "Sercan Ö. Arık"]}, {"title": "The rich man's guide to RAG", "url": "https://olickel.com/rich-mans-guide-to-rag", "source": "curated", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "MAIR: A Massive Benchmark for Evaluating Instructed Retrieval", "url": "https://arxiv.org/abs/2410.10127", "source": "curated", "type": "paper", "summary": "Recent information retrieval (IR) models are pre-trained and instruction-tuned on massive datasets and tasks, enabling them to perform well on a wide range of tasks and potentially generalize to unseen tasks with instructions. However, existing IR benchmarks focus on a limited scope of tasks, making them insufficient for evaluating the latest IR models. In this paper, we propose MAIR (Massive Instructed Retrieval Benchmark), a heterogeneous IR benchmark that includes 126 distinct IR tasks across 6 domains, collected from existing datasets.", "date": "2024-10-14", "authors": ["Weiwei Sun", "Zhengliang Shi", "Jiulong Wu", "Lingyong Yan", "Xinyu Ma", "Yiding Liu", "Min Cao", "Dawei Yin", "Zhaochun Ren"]}, {"title": "Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented Generation", "url": "https://arxiv.org/abs/2409.12941v1", "source": "curated", "type": "paper", "summary": "Large Language Models (LLMs) have demonstrated significant performance improvements across various cognitive tasks. An emerging application is using LLMs to enhance retrieval-augmented generation (RAG) capabilities. These systems require LLMs to understand user queries, retrieve relevant information, and synthesize coherent and accurate responses.", "date": "2024-09-19", "authors": ["Satyapriya Krishna", "Kalpesh Krishna", "Anhad Mohananey", "Steven Schwarcz", "Adam Stambler", "Shyam Upadhyay", "Manaal Faruqui"]}, {"title": "Precise Zero-Shot Dense Retrieval without Relevance Labels", "url": "https://arxiv.org/pdf/2212.10496.pdf", "source": "both", "type": "paper", "summary": "While dense retrieval has been shown effective and efficient across tasks and languages, it remains difficult to create effective fully zero-shot dense retrieval systems when no relevance label is available. In this paper, we recognize the difficulty of zero-shot learning and encoding relevance. Instead, we propose to pivot through Hypothetical Document Embeddings~(HyDE).", "date": "2022-12-20", "authors": ["Luyu Gao", "Xueguang Ma", "Jimmy Lin", "Jamie Callan"]}, {"title": "Learning to Retrieve Iteratively for In-Context Learning", "url": "https://aclanthology.org/2024.emnlp-main.406/", "source": "curated", "type": "paper", "date": "2024-01-01", "summary": "We introduce iterative retrieval, a novel framework that empowers retrievers to make iterative decisions through policy optimization. Finding an optimal portfolio of retrieved items is a combinatorial optimization problem, generally considered NP-hard. This approach provides a learned approximation to such a solution, meeting specific task requirements under a given family of large language models (LLMs).", "authors": null}, {"title": "Drowning in Documents: Consequences of Scaling Reranker Inference", "url": "https://arxiv.org/abs/2411.11767", "source": "curated", "type": "paper", "summary": "Rerankers, typically cross-encoders, are computationally intensive but are frequently used because they are widely assumed to outperform cheaper initial IR systems. We challenge this assumption by measuring reranker performance for full retrieval, not just re-scoring first-stage retrieval. To provide a more robust evaluation, we prioritize strong first-stage retrieval using modern dense embeddings and test rerankers on a variety of carefully chosen, challenging tasks, including internally curated datasets to avoid contamination, and out-of-domain ones.", "date": "2024-11-18", "authors": ["Mathew Jacob", "Erik Lindgren", "Matei Zaharia", "Michael Carbin", "Omar Khattab", "Andrew Drozdov"]}, {"title": "Optimizing RAG with Embedding Tuning - KDnuggets", "url": "https://www.kdnuggets.com/optimizing-rag-with-embedding-tuning", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Top embedding models for RAG", "url": "https://modal.com/blog/embedding-models-article", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Making Text Embedders Few-Shot Learners", "url": "https://arxiv.org/abs/2409.15700", "source": "both", "type": "paper", "summary": "Large language models (LLMs) with decoder-only architectures demonstrate remarkable in-context learning (ICL) capabilities. This feature enables them to effectively handle both familiar and novel tasks by utilizing examples provided within their input context. Recognizing the potential of this capability, we propose leveraging the ICL feature in LLMs to enhance the process of text embedding generation.", "date": "2024-09-24", "authors": ["Chaofan Li", "MingHao Qin", "Shitao Xiao", "Jianlyu Chen", "Kun Luo", "Yingxia Shao", "Defu Lian", "Zheng Liu"]}, {"title": "NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models", "url": "https://arxiv.org/abs/2405.17428", "source": "curated", "type": "paper", "summary": "Decoder-only LLM-based embedding models are beginning to outperform BERT or T5-based embedding models in general-purpose text embedding tasks, including dense vector-based retrieval. In this work, we introduce NV-Embed, incorporating architectural designs, training procedures, and curated datasets to significantly enhance the performance of LLM as a versatile embedding model, while maintaining its simplicity and reproducibility. For model architecture, we propose a latent attention layer to obtain pooled embeddings, which consistently improves retrieval and downstream task accuracy compared to mean pooling or using the last <EOS> token embedding from LLMs.", "date": "2024-05-27", "authors": ["Chankyu Lee", "Rajarshi Roy", "Mengyao Xu", "Jonathan Raiman", "Mohammad Shoeybi", "Bryan Catanzaro", "Wei Ping"]}, {"title": "COCO-LM: Correcting and Contrasting Text Sequences for Language Model Pretraining", "url": "https://arxiv.org/abs/2102.08473", "source": "curated", "type": "paper", "summary": "We present a self-supervised learning framework, COCO-LM, that pretrains Language Models by COrrecting and COntrasting corrupted text sequences. Following ELECTRA-style pretraining, COCO-LM employs an auxiliary language model to corrupt text sequences, upon which it constructs two new tasks for pretraining the main model. The first token-level task, Corrective Language Modeling, is to detect and correct tokens replaced by the auxiliary model, in order to better capture token-level semantics.", "date": "2021-02-16", "authors": ["Yu Meng", "Chenyan Xiong", "Payal Bajaj", "Saurabh Tiwary", "Paul Bennett", "Jiawei Han", "Xia Song"]}, {"title": "Reliable Confidence Intervals for Information Retrieval Evaluation Using Generative A.I", "url": "https://arxiv.org/abs/2407.02464", "source": "curated", "type": "paper", "summary": "The traditional evaluation of information retrieval (IR) systems is generally very costly as it requires manual relevance annotation from human experts. Recent advancements in generative artificial intelligence -- specifically large language models (LLMs) -- can generate relevance annotations at an enormous scale with relatively small computational costs. Potentially, this could alleviate the costs traditionally associated with IR evaluation and make it applicable to numerous low-resource applications.", "date": "2024-07-02", "authors": ["Harrie Oosterhuis", "Rolf Jagerman", "Zhen Qin", "Xuanhui Wang", "Michael Bendersky"]}, {"title": "Ranked List Truncation for Large Language Model-based Re-Ranking", "url": "https://doi.org/10.1145/3626772.3657864", "source": "curated", "type": "paper", "date": null, "summary": null, "authors": null}, {"title": "Is Semantic Chunking Worth the Computational Cost?", "url": "https://arxiv.org/abs/2410.13070", "source": "curated", "type": "paper", "summary": "Recent advances in Retrieval-Augmented Generation (RAG) systems have popularized semantic chunking, which aims to improve retrieval performance by dividing documents into semantically coherent segments. Despite its growing adoption, the actual benefits over simpler fixed-size chunking, where documents are split into consecutive, fixed-size segments, remain unclear. This study systematically evaluates the effectiveness of semantic chunking using three common retrieval-related tasks: document retrieval, evidence retrieval, and retrieval-based answer generation.", "date": "2024-10-16", "authors": ["Renyi Qu", "Ruixuan Tu", "Forrest Bao"]}, {"title": "Dense X Retrieval: What Retrieval Granularity Should We Use?", "url": "https://aclanthology.org/2024.emnlp-main.845/", "source": "both", "type": "paper", "date": "2024-01-01", "summary": "Dense retrieval has become a prominent method to obtain relevant context or world knowledge in open-domain NLP tasks. When we use a learned dense retriever on a retrieval corpus at inference time, an often-overlooked design choice is the retrieval unit in which the corpus is indexed, e.g. document, passage, or sentence.", "authors": null}, {"title": "The use of MMR, diversity-based reranking for reordering documents and producing summaries", "url": "https://doi.org/10.1145/290941.291025", "source": "curated", "type": "paper", "date": null, "summary": null, "authors": null}, {"title": "Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models", "url": "https://arxiv.org/abs/2310.07712", "source": "curated", "type": "paper", "summary": "Large language models (LLMs) exhibit positional bias in how they use context, which especially complicates listwise ranking. To address this, we propose permutation self-consistency, a form of self-consistency over ranking list outputs of black-box LLMs. Our key idea is to marginalize out different list orders in the prompt to produce an order-independent ranking with less positional bias.", "date": "2023-10-11", "authors": ["Raphael Tang", "Xinyu Zhang", "Xueguang Ma", "Jimmy Lin", "Ferhan Ture"]}, {"title": "Distillation and Refinement of Reasoning in Small Language Models for Document Re-ranking", "url": "https://arxiv.org/abs/2504.03947", "source": "curated", "type": "paper", "summary": "We present a novel approach for training small language models for reasoning-intensive document ranking that combines knowledge distillation with reinforcement learning optimization. While existing methods often rely on expensive human annotations or large black-box language models, our methodology leverages web data and a teacher LLM to automatically generate high-quality training examples with relevance explanations. By framing document ranking as a reinforcement learning problem and incentivizing explicit reasoning capabilities, we train a compact 3B parameter language model that achieves state-of-the-art performance on the BRIGHT benchmark.", "date": "2025-04-04", "authors": ["Chris Samarinas", "Hamed Zamani"]}, {"title": "Zero-Shot Dense Retrieval with Embeddings from Relevance Feedback", "url": "https://arxiv.org/abs/2410.21242", "source": "both", "type": "paper", "summary": "Building effective dense retrieval systems remains difficult when relevance supervision is not available. Recent work has looked to overcome this challenge by using a Large Language Model (LLM) to generate hypothetical documents that can be used to find the closest real document. However, this approach relies solely on the LLM to have domain-specific knowledge relevant to the query, which may not be practical.", "date": "2024-10-28", "authors": ["Nour Jedidi", "Yung-Sung Chuang", "Leslie Shing", "James Glass"]}, {"title": "Qwen/Qwen3-Reranker-0.6B · Hugging Face", "url": "https://huggingface.co/Qwen/Qwen3-Reranker-0.6B", "source": "curated", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "lightgbm.LGBMRanker — LightGBM 4.5.0.99 documentation", "url": "https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRanker.html", "type": "documentation", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Measuring Search Relevance, Part 2: nDCG Deep Dive : r/RedditEng", "url": "https://www.reddit.com/r/RedditEng/comments/y6idrl/measuring_search_relevance_part_2_ndcg_deep_dive/?rdt=51927", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Learning to Rank — xgboost 2.1.1 documentation", "url": "https://xgboost.readthedocs.io/en/latest/tutorials/learning_to_rank.html#references", "type": "documentation", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "intfloat/e5-base-v2 · Hugging Face", "url": "https://huggingface.co/intfloat/e5-base-v2", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Doug Turnbull's Blog", "url": "https://softwaredoug.com/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Elasticsearch Learning to Rank: the documentation — Elasticsearch Learning to Rank documentation", "url": "https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/", "type": "documentation", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Welcome to GraphRAG", "url": "https://microsoft.github.io/graphrag/", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "cross-encoder/ms-marco-MiniLM-L-6-v2 · Hugging Face", "url": "https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "google/frames-benchmark · Datasets at Hugging Face", "url": "https://huggingface.co/datasets/google/frames-benchmark", "type": "tool", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "intfloat/e5-large-v2 · Hugging Face", "url": "https://huggingface.co/intfloat/e5-large-v2", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "The use of MMR, diversity-based reranking for reordering documents and producing summaries | Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval", "url": "https://dl.acm.org/doi/10.1145/290941.291025", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "BAAI/bge-m3 · Hugging Face", "url": "https://huggingface.co/BAAI/bge-m3", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Pyserini Reproductions", "url": "https://castorini.github.io/pyserini/2cr/beir.html", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "oraios/serena: A powerful coding agent toolkit providing semantic retrieval and editing capabilities (MCP server & Agno integration)", "url": "https://github.com/oraios/serena", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[2404.07220] Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers", "url": "https://arxiv.org/abs/2404.07220", "type": "paper", "source": "chrome", "summary": "Retrieval-Augmented Generation (RAG) is a prevalent approach to infuse a private knowledge base of documents with Large Language Models (LLM) to build Generative Q\\&A (Question-Answering) systems. However, RAG accuracy becomes increasingly challenging as the corpus of documents scales up, with Retrievers playing an outsized role in the overall RAG accuracy by extracting the most relevant document from the corpus to provide context to the LLM. In this paper, we propose the 'Blended RAG' method of leveraging semantic search techniques, such as Dense Vector indexes and Sparse Encoder indexes, blended with hybrid query strategies.", "date": "2024-03-22", "authors": ["Kunal Sawarkar", "Abhilasha Mangal", "Shivam Raj Solanki"]}, {"title": "[2205.09707] PLAID: An Efficient Engine for Late Interaction Retrieval", "url": "https://arxiv.org/abs/2205.09707", "type": "paper", "source": "chrome", "summary": "Pre-trained language models are increasingly important components across multiple information retrieval (IR) paradigms. Late interaction, introduced with the ColBERT model and recently refined in ColBERTv2, is a popular paradigm that holds state-of-the-art status across many benchmarks. To dramatically speed up the search latency of late interaction, we introduce the Performance-optimized Late Interaction Driver (PLAID).", "date": "2022-05-19", "authors": ["Keshav Santhanam", "Omar Khattab", "Christopher Potts", "Matei Zaharia"]}, {"title": "[2507.10411] Am I on the Right Track? What Can Predicted Query Performance Tell Us about the Search Behaviour of Agentic RAG", "url": "https://arxiv.org/abs/2507.10411", "type": "paper", "source": "chrome", "summary": "Agentic Retrieval-Augmented Generation (RAG) is a new paradigm where the reasoning model decides when to invoke a retriever (as a \"tool\") when answering a question. This paradigm, exemplified by recent research works such as Search-R1, enables the model to decide when to search and obtain external information. However, the queries generated by such Agentic RAG models and the role of the retriever in obtaining high-quality answers remain understudied.", "date": "2025-07-14", "authors": ["Fangzheng Tian", "Jinyuan Fang", "Debasis Ganguly", "Zaiqiao Meng", "Craig Macdonald"]}, {"title": "[2509.07253] Benchmarking Information Retrieval Models on Complex Retrieval Tasks", "url": "https://arxiv.org/abs/2509.07253", "type": "paper", "source": "chrome", "summary": "Large language models (LLMs) are incredible and versatile tools for text-based tasks that have enabled countless, previously unimaginable, applications. Retrieval models, in contrast, have not yet seen such capable general-purpose models emerge. To achieve this goal, retrieval models must be able to perform complex retrieval tasks, where queries contain multiple parts, constraints, or requirements in natural language.", "date": "2025-09-08", "authors": ["Julian Killingback", "Hamed Zamani"]}, {"title": "Introducing RTEB: A New Standard for Retrieval Evaluation", "url": "https://huggingface.co/blog/rteb", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "mGTE: Generalized Long-Context Text Representation and Reranking Models for Multilingual Text Retrieval - ACL Anthology", "url": "https://aclanthology.org/2024.emnlp-industry.103/", "type": "paper", "source": "chrome", "date": "2024-01-01", "summary": "We present systematic efforts in building long-context multilingual text representation model (TRM) and reranker from scratch for text retrieval. We first introduce a text encoder (base size) enhanced with RoPE and unpadding, pre-trained in a native 8192-token context (longer than 512 of previous multilingual encoders). Then we construct a hybrid TRM and a cross-encoder reranker by contrastive learning.", "authors": null}, {"title": "[2410.05801] Retrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation", "url": "https://arxiv.org/abs/2410.05801", "type": "paper", "source": "chrome", "summary": "Recent Retrieval Augmented Generation (RAG) aims to enhance Large Language Models (LLMs) by incorporating extensive knowledge retrieved from external sources. However, such approach encounters some challenges: Firstly, the original queries may not be suitable for precise retrieval, resulting in erroneous contextual knowledge; Secondly, the language model can easily generate inconsistent answer with external references due to their knowledge boundary limitation. To address these issues, we propose the chain-of-verification (CoV-RAG) to enhance the external retrieval correctness and internal generation consistency.", "date": "2024-10-08", "authors": ["Bolei He", "Nuo Chen", "Xinran He", "Lingyong Yan", "Zhenkai Wei", "Jinchang Luo", "Zhen-Hua Ling"]}, {"title": "sionic-ai/muvera-py: Python Implementation of MUVERA (Multi-Vector Retrieval via Fixed Dimensional Encodings)", "url": "https://github.com/sionic-ai/muvera-py", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}]}, {"name": "LLM Self-Critique", "items": [{"title": "Can Large Language Models Really Improve by Self-critiquing Their Own Plans?", "url": "https://arxiv.org/abs/2310.08118", "source": "curated", "type": "paper", "summary": "There have been widespread claims about Large Language Models (LLMs) being able to successfully verify or self-critique their candidate solutions in reasoning problems in an iterative mode. Intrigued by those claims, in this paper we set out to investigate the verification/self-critiquing abilities of large language models in the context of planning. We evaluate a planning system that employs LLMs for both plan generation and verification.", "date": "2023-10-12", "authors": ["Karthik Valmeekam", "Matthew Marquez", "Subbarao Kambhampati"]}, {"title": "LLMs cannot find reasoning errors, but can correct them given the error location", "url": "https://aclanthology.org/2024.findings-acl.826/", "source": "curated", "type": "paper", "date": "2024-01-01", "summary": "While self-correction has shown promise in improving LLM outputs in terms of style and quality (e.g. Chen et al., 2023b; Madaan et al.,2023), recent attempts to self-correct logical or reasoning errors often cause correct answers to become incorrect, resulting in worse performances overall (Huang et al., 2023). In this paper, we show that poor self-correction performance stems from LLMs’ inability tofind logical mistakes, rather than their ability to correct a known mistake.", "authors": null}, {"title": "Self-Contradictory Reasoning Evaluation and Detection", "url": "https://arxiv.org/abs/2311.09603", "source": "curated", "type": "paper", "summary": "In a plethora of recent work, large language models (LLMs) demonstrated impressive reasoning ability, but many proposed downstream reasoning tasks only focus on final answers. Two fundamental questions persist: 1) how consistent is the reasoning, and 2) can models detect unreliable reasoning? In this paper, we investigate self-contradictory (Self-Contra) reasoning, where the model reasoning does not support its answers.", "date": "2023-11-16", "authors": ["Ziyi Liu", "Soumya Sanyal", "Isabelle Lee", "Yongkang Du", "Rahul Gupta", "Yang Liu", "Jieyu Zhao"]}, {"title": "Large Language Models Cannot Self-Correct Reasoning Yet", "url": "https://arxiv.org/pdf/2310.01798.pdf", "source": "both", "type": "paper", "summary": "Large Language Models (LLMs) have emerged as a groundbreaking technology with their unparalleled text generation capabilities across various applications. Nevertheless, concerns persist regarding the accuracy and appropriateness of their generated content. A contemporary methodology, self-correction, has been proposed as a remedy to these issues.", "date": "2023-10-03", "authors": ["Jie Huang", "Xinyun Chen", "Swaroop Mishra", "Huaixiu Steven Zheng", "Adams Wei Yu", "Xinying Song", "Denny Zhou"]}, {"title": "When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs", "url": "https://aclanthology.org/2024.tacl-1.78/", "source": "curated", "type": "paper", "date": "2024-01-01", "summary": "Self-correction is an approach to improving responses from large language models (LLMs) by refining the responses using LLMs during inference. Prior work has proposed various self-correction frameworks using different sources of feedback, including self-evaluation and external feedback. However, there is still no consensus on the question of when LLMs can correct their own mistakes, as recent studies also report negative results.", "authors": null}]}, {"name": "NLP for Law (Models, Tasks, and Datasets)", "items": [{"title": "GitHub - dtuggener/LEDGAR_provision_classification", "url": "https://github.com/dtuggener/LEDGAR_provision_classification?tab=readme-ov-file", "source": "curated", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "CLERC: A Dataset for Legal Case Retrieval and Retrieval-Augmented Analysis Generation", "url": "https://arxiv.org/abs/2406.17186", "source": "curated", "type": "paper", "summary": "Legal professionals need to write analyses that rely on citations to relevant precedents, i.e., previous case decisions. Intelligent systems assisting legal professionals in writing such documents provide great benefits but are challenging to design. Such systems need to help locate, summarize, and reason over salient precedents in order to be useful.", "date": "2024-06-24", "authors": ["Abe Bohan Hou", "Orion Weller", "Guanghui Qin", "Eugene Yang", "Dawn Lawrie", "Nils Holzenberger", "Andrew Blair-Stanek", "Benjamin Van Durme"]}, {"title": "ACORD: An Expert-Annotated Retrieval Dataset for Legal Contract Drafting", "url": "https://arxiv.org/abs/2501.06582", "source": "both", "type": "paper", "summary": "Information retrieval, specifically contract clause retrieval, is foundational to contract drafting because lawyers rarely draft contracts from scratch; instead, they locate and revise the most relevant precedent. We introduce the Atticus Clause Retrieval Dataset (ACORD), the first retrieval benchmark for contract drafting fully annotated by experts. ACORD focuses on complex contract clauses such as Limitation of Liability, Indemnification, Change of Control, and Most Favored Nation.", "date": "2025-01-11", "authors": ["Steven H. Wang", "Maksim Zubkov", "Kexin Fan", "Sarah Harrell", "Yuyang Sun", "Wei Chen", "Andreas Plesner", "Roger Wattenhofer"]}, {"title": "pile-of-law/pile-of-law · Datasets at Hugging Face", "url": "https://huggingface.co/datasets/pile-of-law/pile-of-law", "source": "curated", "type": "tool", "summary": null, "date": null, "authors": null}, {"title": "Plain English Summarization of Contracts", "url": "https://aclanthology.org/W19-2201/", "source": "curated", "type": "paper", "date": "2019-01-01", "summary": "Unilateral legal contracts, such as terms of service, play a substantial role in modern digital life. However, few read these documents before accepting the terms within, as they are too long and the language too complicated. We propose the task of summarizing such legal documents in plain English, which would enable users to have a better understanding of the terms they are accepting.", "authors": null}, {"title": "MAUD: An Expert-Annotated Legal NLP Dataset for Merger Agreement Understanding", "url": "https://arxiv.org/abs/2301.00876", "source": "curated", "type": "paper", "summary": "Reading comprehension of legal text can be a particularly challenging task due to the length and complexity of legal clauses and a shortage of expert-annotated datasets. To address this challenge, we introduce the Merger Agreement Understanding Dataset (MAUD), an expert-annotated reading comprehension dataset based on the American Bar Association's 2021 Public Target Deal Points Study, with over 39,000 examples and over 47,000 total annotations. Our fine-tuned Transformer baselines show promising results, with models performing well above random on most questions.", "date": "2023-01-02", "authors": ["Steven H. Wang", "Antoine Scardigli", "Leonard Tang", "Wei Chen", "Dimitry Levkin", "Anya Chen", "Spencer Ball", "Thomas Woodside", "Oliver Zhang", "Dan Hendrycks"]}, {"title": "The Material Contracts Corpus", "url": "https://arxiv.org/abs/2504.02864", "source": "both", "type": "paper", "summary": "This paper introduces the Material Contracts Corpus (MCC), a publicly available dataset comprising over one million contracts filed by public companies with the U.S. Securities and Exchange Commission (SEC) between 2000 and 2023. The MCC facilitates empirical research on contract design and legal language, and supports the development of AI-based legal tools.", "date": "2025-04-01", "authors": ["Peter Adelson", "Julian Nyarko"]}, {"title": "LeXFiles and LegalLAMA: Facilitating English Multinational Legal Language Model Development", "url": "https://arxiv.org/abs/2305.07507", "source": "both", "type": "paper", "summary": "In this work, we conduct a detailed analysis on the performance of legal-oriented pre-trained language models (PLMs). We examine the interplay between their original objective, acquired knowledge, and legal language understanding capacities which we define as the upstream, probing, and downstream performance, respectively. We consider not only the models' size but also the pre-training corpora used as important dimensions in our study.", "date": "2023-05-12", "authors": ["Ilias Chalkidis", "Nicolas Garneau", "Catalina Goanta", "Daniel Martin Katz", "Anders Søgaard"]}, {"title": "Thomson Reuters Best Practices for Benchmarking AI for Legal Research - Thomson Reuters Institute", "url": "https://www.thomsonreuters.com/en-us/posts/innovation/thomson-reuters-best-practices-for-benchmarking-ai-for-legal-research/", "source": "both", "type": "news", "summary": null, "date": null, "authors": null}, {"title": "Artificial Intelligence and Legal Analysis: Implications for Legal Education and the Profession", "url": "https://arxiv.org/pdf/2502.03487", "source": "both", "type": "paper", "summary": "This article reports the results of a study examining the ability of legal and non-legal Large Language Models to perform legal analysis using the Issue-Rule-Application-Conclusion framework. LLMs were tested on legal reasoning tasks involving rule analysis and analogical reasoning. The results show that LLMs can conduct basic IRAC analysis, but are limited by brief responses lacking detail, an inability to commit to answers, false confidence, and hallucinations.", "date": "2025-02-04", "authors": ["Lee Peoples"]}, {"title": "ACORD | atticus-project", "url": "https://www.atticusprojectai.org/acord", "source": "both", "type": "tool", "summary": null, "date": null, "authors": null}, {"title": "Natural Language Processing for the Legal Domain: A Survey of Tasks, Datasets, Models, and Challenges", "url": "https://arxiv.org/abs/2410.21306", "source": "curated", "type": "paper", "summary": "Natural Language Processing (NLP) is revolutionising the way both professionals and laypersons operate in the legal field. The considerable potential for NLP in the legal sector, especially in developing computational assistance tools for various legal processes, has captured the interest of researchers for years. This survey follows the Preferred Reporting Items for Systematic Reviews and Meta-Analyses framework, reviewing 154 studies, with a final selection of 131 after manual filtering.", "date": "2024-10-25", "authors": ["Farid Ariai", "Joel Mackenzie", "Gianluca Demartini"]}, {"title": "Precise Legal Sentence Boundary Detection for Retrieval at Scale: NUPunkt and CharBoundary", "url": "https://arxiv.org/abs/2504.04131", "source": "both", "type": "paper", "summary": "We present NUPunkt and CharBoundary, two sentence boundary detection libraries optimized for high-precision, high-throughput processing of legal text in large-scale applications such as due diligence, e-discovery, and legal research. These libraries address the critical challenges posed by legal documents containing specialized citations, abbreviations, and complex sentence structures that confound general-purpose sentence boundary detectors. Our experimental evaluation on five diverse legal datasets comprising over 25,000 documents and 197,000 annotated sentence boundaries demonstrates that NUPunkt achieves 91.1% precision while processing 10 million characters per second with modest memory requirements (432 MB).", "date": "2025-04-05", "authors": ["Michael J Bommarito", "Daniel Martin Katz", "Jillian Bommarito"]}, {"title": "A Reasoning-Focused Legal Retrieval Benchmark", "url": "https://reglab.github.io/legal-rag-benchmarks/", "source": "curated", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "Transformer-Based Extraction of Statutory Definitions from the U.S. Code", "url": "https://arxiv.org/abs/2504.16353", "source": "both", "type": "paper", "summary": "Automatic extraction of definitions from legal texts is critical for enhancing the comprehension and clarity of complex legal corpora such as the United States Code (U.S.C.). We present an advanced NLP system leveraging transformer-based architectures to automatically extract defined terms, their definitions, and their scope from the U.S.C. We address the challenges of automatically identifying legal definitions, extracting defined terms, and determining their scope within this complex corpus of over 200,000 pages of federal statutory law.", "date": "2025-04-23", "authors": ["Arpana Hosabettu", "Harsh Shah"]}, {"title": "Identifying Legal Holdings with LLMs: A Systematic Study of Performance, Scale, and Memorization", "url": "https://arxiv.org/abs/2505.02172v1", "source": "curated", "type": "paper", "summary": "As large language models (LLMs) continue to advance in capabilities, it is essential to assess how they perform on established benchmarks. In this study, we present a suite of experiments to assess the performance of modern LLMs (ranging from 3B to 90B+ parameters) on CaseHOLD, a legal benchmark dataset for identifying case holdings. Our experiments demonstrate scaling effects - performance on this task improves with model size, with more capable models like GPT4o and AmazonNovaPro achieving macro F1 scores of 0.744 and 0.720 respectively.", "date": "2025-05-04", "authors": ["Chuck Arvin"]}, {"title": "Stanford Law creates largest-ever public dataset of corporate contracts", "url": "https://news.stanford.edu/stories/2025/04/law-school-dataset-sec-material-contracts-corpus", "source": "both", "type": "news", "summary": null, "date": null, "authors": null}, {"title": "Practical Law - Legal Resources & Know-How for Professionals | Thomson Reuters", "url": "https://legal.thomsonreuters.com/en/products/practical-law", "type": "news", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Spellbook - AI Contract Drafting & Review", "url": "https://www.spellbook.legal/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "AI in focus: Using AI to predict case outcomes", "url": "https://www.taylorwessing.com/en/insights-and-events/insights/2024/07/ai-in-focus-using-ai-to-predict-case-outcomes", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "lexlms/legal-roberta-large · Hugging Face", "url": "https://huggingface.co/lexlms/legal-roberta-large", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "SEC.gov | Understand Messages Reported by EDGAR", "url": "https://www.sec.gov/submit-filings/filer-support-resources/how-do-i-guides/understand-messages-reported-edgar#alpha", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[2502.09204] Logical Lease Litigation: Prolog and LLMs for Rental Law Compliance in New York", "url": "https://arxiv.org/abs/2502.09204", "type": "paper", "source": "chrome", "summary": "Legal cases require careful logical reasoning following the laws, whereas interactions with non-technical users must be in natural language. As an application combining logical reasoning using Prolog and natural language processing using large language models (LLMs), this paper presents a novel approach and system, LogicLease, to automate the analysis of landlord-tenant legal cases in the state of New York. LogicLease determines compliance with relevant legal requirements by analyzing case descriptions and citing all relevant laws.", "date": "2025-02-13", "authors": ["Sanskar Sehgal", "Yanhong A. Liu"]}, {"title": "neelguha/legal-ml-datasets: A collection of datasets and tasks for legal machine learning", "url": "https://github.com/neelguha/legal-ml-datasets", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Material Contracts Corpus", "url": "https://mcc.law.stanford.edu/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "TheAtticusProject/maud", "url": "https://github.com/TheAtticusProject/maud/tree/main", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Home - NLLP 2025", "url": "https://nllpw.org/workshop/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Home - NLLP 2025", "url": "https://nllpw.org/workshop/call/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "SEC.gov | EDGAR Full Text Search", "url": "https://www.sec.gov/edgar/search/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "The Anti-ChatGPT: Thomson Reuters' multi-agent system slashes 20-hour tasks to 10 minutes", "url": "https://venturebeat.com/ai/the-anti-chatgpt-thomson-reuters-multi-agent-system-slashes-20-hour-tasks-to", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "From Startup Vision to AI Breakthrough: One Year with Safe Sign - Thomson Reuters Institute", "url": "https://blogs.thomsonreuters.com/en-us/innovation/from-startup-vision-to-ai-breakthrough-one-year-with-safe-sign/", "type": "news", "source": "chrome", "summary": null, "date": null, "authors": null}]}, {"name": "NLP Tools, Libraries, and Code Resources", "items": [{"title": "GitHub - StacklokLabs/promptwright: Generate large synthetic data using an LLM", "url": "https://github.com/StacklokLabs/promptwright", "source": "curated", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "GitHub - joaopalotti/trectools: A simple toolkit to process TREC files in Python.", "url": "https://github.com/joaopalotti/trectools/tree/master", "source": "both", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "GitHub - deepset-ai/haystack: AI orchestration framework to build customizable, production-ready LLM applications. Connect components (models, vector DBs, file converters) to pipelines or agents that can interact with your data. With advanced retrieval methods, it's best suited for building RAG, question answering, semantic search or conversational agent chatbots.", "url": "https://github.com/deepset-ai/haystack", "source": "both", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "ModernBERT/examples at main · AnswerDotAI/ModernBERT", "url": "https://github.com/AnswerDotAI/ModernBERT/tree/main/examples", "source": "both", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "GitHub - urchade/GLiNER: Generalist and Lightweight Model for Named Entity Recognition (Extract any entity types from texts) @ NAACL 2024", "url": "https://github.com/urchade/GLiNER", "source": "curated", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "GitHub - moxin-org/Moxin-LLM", "url": "https://github.com/moxin-org/Moxin-LLM", "source": "curated", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "GitHub - Optum/long-medical-document-lms: Explain and train language models that extract information from long medical documents with the Masked Sampling Procedure (MSP)", "url": "https://github.com/Optum/long-medical-document-lms", "source": "both", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "GitHub - amazon-science/RAGChecker: RAGChecker: A Fine-grained Framework For Diagnosing RAG", "url": "https://github.com/amazon-science/RAGChecker", "source": "curated", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "Building a Retrieval-Augmented Generation (RAG) System with DeepSeek R1: A Step-by-Step Guide", "url": "https://www.marktechpost.com/2025/01/27/building-a-retrieval-augmented-generation-rag-system-with-deepseek-r1-a-step-by-step-guide/", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Building a fully local \"deep researcher\" with DeepSeek-R1", "url": "https://www.youtube.com/watch?v=sGUjmyfof4Q&t=91s", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "GitHub - langchain-ai/ollama-deep-researcher: Fully local web research and report writing assistant", "url": "https://github.com/langchain-ai/ollama-deep-researcher", "source": "curated", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "Fine-tune ModernBERT for RAG with Synthetic Data", "url": "https://huggingface.co/blog/sdiazlor/fine-tune-modernbert-for-rag-with-synthetic-data", "source": "curated", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Fine-tune ModernBERT for text classification using synthetic data", "url": "https://huggingface.co/blog/davidberenstein1957/fine-tune-modernbert-on-synthetic-data", "source": "curated", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "https://machinelearningmastery.com/a-complete-introduction-to-using-bert-models/", "url": "https://machinelearningmastery.com/a-complete-introduction-to-using-bert-models/", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "LLMs-from-scratch/setup/01_optional-python-setup-preferences at main · rasbt/LLMs-from-scratch", "url": "https://github.com/rasbt/LLMs-from-scratch/tree/main/setup/01_optional-python-setup-preferences", "source": "both", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "Mistral OCR | Mistral AI", "url": "https://mistral.ai/news/mistral-ocr", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "jinaai/jina-reranker-v2-base-multilingual · Hugging Face", "url": "https://huggingface.co/jinaai/jina-reranker-v2-base-multilingual", "source": "both", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "Training and Finetuning Reranker Models with Sentence Transformers v4", "url": "https://huggingface.co/blog/train-reranker", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Loss Overview — Sentence Transformers documentation", "url": "https://sbert.net/docs/cross_encoder/loss_overview.html", "source": "both", "type": "documentation", "summary": null, "date": null, "authors": null}, {"title": "https://www.kdnuggets.com/lesser-known-python-functions-that-are-super-useful", "url": "https://www.kdnuggets.com/lesser-known-python-functions-that-are-super-useful", "source": "curated", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "GitHub - hiyouga/LLaMA-Factory: Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024)", "url": "https://github.com/hiyouga/LLaMA-Factory", "source": "both", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "GitHub - alea-institute/nupunkt: Next-generation Punkt sentence boundary detection with zero dependencies", "url": "https://github.com/alea-institute/nupunkt", "source": "curated", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "GitHub - autogluon/autogluon: Fast and Accurate ML in 3 Lines of Code", "url": "https://github.com/autogluon/autogluon", "source": "both", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "GitHub - jonhue/activeft: PyTorch library for Active Fine-Tuning", "url": "https://github.com/jonhue/activeft", "source": "both", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "Build an AI-powered document processing platform with open source NER model and LLM on Amazon SageMaker | Amazon Web Services", "url": "https://aws.amazon.com/blogs/machine-learning/build-an-ai-powered-document-processing-platform-with-open-source-ner-model-and-llm-on-amazon-sagemaker/", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Breaking Out of Beginner: Python Patterns for Intermediate Data Scientists - KDnuggets", "url": "https://www.kdnuggets.com/breaking-out-of-beginner-python-patterns-for-intermediate-data-scientists", "source": "curated", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "GitHub - casetext/r-and-r: Code for the \"Long Context Needs Some R&R\" paper.", "url": "https://github.com/casetext/r-and-r", "source": "curated", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "GitHub - lightonai/fast-plaid: High-Performance Engine for Multi-Vector Search", "url": "https://github.com/lightonai/fast-plaid", "source": "both", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "Qwen/Qwen3-Reranker-8B · Hugging Face", "url": "https://huggingface.co/Qwen/Qwen3-Reranker-8B", "source": "curated", "type": "repo", "summary": null, "date": null, "authors": null}, {"title": "Chat playground | Azure OpenAI Studio", "url": "https://oai.azure.com/portal/25d2c8d927ea4b339550f6169e5028f8/chat?tenantid=e205bfab-7c3a-4369-86f3-030001469257", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Console Home | Console Home | us-east-2", "url": "https://us-east-2.console.aws.amazon.com/console/home?region=us-east-2#", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "How to Make Your Code Reviewer Fall in Love with You · mtlynch.io", "url": "https://mtlynch.io/code-review-love/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "My favourite Git commit | dhwthompson.com", "url": "https://dhwthompson.com/2019/my-favourite-git-commit", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Amazon EC2 Instance Comparison", "url": "https://instances.vantage.sh/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Inputs — sagemaker 2.232.1 documentation", "url": "https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html#sagemaker.inputs.TrainingInput", "type": "documentation", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Long context prompting tips - Anthropic", "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/long-context-tips#example-multi-document-structure", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Leaked meta prompt, seen at https://x.com/amebagpt/status/1841177927569838519", "url": "https://gist.github.com/philschmid/3a0ecc9e45763716f4dd9c36b6445fca", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Paper Review: Are LLMs Good at Search? | by David Ken | Thomson Reuters Labs | Medium", "url": "https://medium.com/tr-labs-ml-engineering-blog/paper-review-are-llms-good-at-search-1d8724527132", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Thomson Reuters Labs – Medium", "url": "https://medium.com/tr-labs-ml-engineering-blog", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Bias and Fairness in Natural Language Processing | by Navid Rekabsaz | Thomson Reuters Labs | Jan, 2025 | Medium", "url": "https://medium.com/tr-labs-ml-engineering-blog/bias-and-fairness-in-natural-language-processing-7663a6d33932", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Fine-tuning LLMs: A Practical Journey with LLaMA Factory | by Guilherme Yambanis Thomaz | Thomson Reuters Labs | Mar, 2025 | Medium", "url": "https://medium.com/tr-labs-ml-engineering-blog/fine-tuning-llms-a-practical-journey-with-llama-factory-98c1fb2658b4", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "langchain-ai/langsmith-sdk: LangSmith Client SDK Implementations", "url": "https://github.com/langchain-ai/langsmith-sdk", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Tool use with Claude - Anthropic", "url": "https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/overview#single-tool-example", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "amazon-science/CriSPO: Implementation of AAAI-2025 paper -- \"CriSPO: Multi-Aspect Critique-Suggestion-guided Automatic Prompt Optimization for Text Generation\"", "url": "https://github.com/amazon-science/CriSPO", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "g6e.xlarge pricing and specs - Vantage", "url": "https://instances.vantage.sh/aws/ec2/g6e.xlarge?currency=USD", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "thomsonreuters/query-based-rrf", "url": "https://github.com/thomsonreuters/query-based-rrf/", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "- Vibe Coding 8 -- Clod Code", "url": "https://joelgrus.com/2025/08/25/vibe-coding-8-clod-code/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Agent Skills - Claude Docs", "url": "https://docs.claude.com/en/docs/agents-and-tools/agent-skills/overview", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Equipping agents for the real world with Agent Skills \\ Anthropic", "url": "https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Tech Stack for Vibe Coding Modern Applications - KDnuggets", "url": "https://www.kdnuggets.com/tech-stack-for-vibe-coding-modern-applications", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Data science portfolio by Andrey Lukyanenko", "url": "https://erlemar.github.io/", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Hashing feature transformation using Totally Random Trees — scikit-learn 0.19.1 documentation", "url": "http://scikit-learn.org/stable/auto_examples/ensemble/plot_random_forest_embedding.html#sphx-glr-auto-examples-ensemble-plot-random-forest-embedding-py", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Alchemy - Open Source AI", "url": "https://alchemy.cs.washington.edu/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}]}, {"name": "NLP for Health", "items": [{"title": "RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism", "url": "https://arxiv.org/abs/1608.05745", "source": "curated", "type": "paper", "summary": "Accuracy and interpretability are two dominant features of successful predictive models. Typically, a choice must be made in favor of complex black box models such as recurrent neural networks (RNN) for accuracy versus less accurate but more interpretable traditional models such as logistic regression. This tradeoff poses challenges in medicine where both accuracy and interpretability are important.", "date": "2016-08-19", "authors": ["Edward Choi", "Mohammad Taha Bahadori", "Joshua A. Kulas", "Andy Schuetz", "Walter F. Stewart", "Jimeng Sun"]}, {"title": "Explainable Prediction of Medical Codes from Clinical Text", "url": "https://aclanthology.org/N18-1100/", "source": "curated", "type": "paper", "date": "2018-01-01", "summary": "Clinical notes are text documents that are created by clinicians for each patient encounter. They are typically accompanied by medical codes, which describe the diagnosis and treatment. Annotating these codes is labor intensive and error prone; furthermore, the connection between the codes and the text is not annotated, obscuring the reasons and details behind specific diagnoses and treatments.", "authors": null}, {"title": "Code Synonyms Do Matter: Multiple Synonyms Matching Network for Automatic ICD Coding", "url": "https://arxiv.org/abs/2203.01515", "source": "curated", "type": "paper", "summary": "Automatic ICD coding is defined as assigning disease codes to electronic medical records (EMRs). Existing methods usually apply label attention with code representations to match related text snippets. Unlike these works that model the label with the code hierarchy or description, we argue that the code synonyms can provide more comprehensive knowledge based on the observation that the code expressions in EMRs vary from their descriptions in ICD.", "date": "2022-03-03", "authors": ["Zheng Yuan", "Chuanqi Tan", "Songfang Huang"]}, {"title": "MIMIC-IV, a freely accessible electronic health record dataset", "url": "https://www.nature.com/articles/s41597-022-01899-x", "source": "curated", "type": "paper", "date": null, "summary": null, "authors": null}, {"title": "Limitations of Transformers on Clinical Text Classification", "url": "https://ieeexplore.ieee.org/abstract/document/9364676", "source": "curated", "type": "paper", "date": null, "summary": null, "authors": null}, {"title": "CliniQG4QA: Generating Diverse Questions for Domain Adaptation of Clinical Question Answering", "url": "https://arxiv.org/abs/2010.16021", "source": "curated", "type": "paper", "summary": "Clinical question answering (QA) aims to automatically answer questions from medical professionals based on clinical texts. Studies show that neural QA models trained on one corpus may not generalize well to new clinical texts from a different institute or a different patient group, where large-scale QA pairs are not readily available for model retraining. To address this challenge, we propose a simple yet effective framework, CliniQG4QA, which leverages question generation (QG) to synthesize QA pairs on new clinical contexts and boosts QA models without requiring manual annotations.", "date": "2020-10-30", "authors": ["Xiang Yue", "Xinliang Frederick Zhang", "Ziyu Yao", "Simon Lin", "Huan Sun"]}, {"title": "Pretrained Language Models for Biomedical and Clinical Tasks: Understanding and Extending the State-of-the-Art", "url": "https://aclanthology.org/2020.clinicalnlp-1.17/", "source": "curated", "type": "paper", "date": "2020-01-01", "summary": "A large array of pretrained models are available to the biomedical NLP (BioNLP) community. Finding the best model for a particular task can be difficult and time-consuming. For many applications in the biomedical and clinical domains, it is crucial that models can be built quickly and are highly accurate.", "authors": null}, {"title": "RadQA: A Question Answering Dataset to Improve Comprehension of Radiology Reports", "url": "https://aclanthology.org/2022.lrec-1.672/", "source": "curated", "type": "paper", "date": "2022-01-01", "summary": "We present a radiology question answering dataset, RadQA, with 3074 questions posed against radiology reports and annotated with their corresponding answer spans (resulting in a total of 6148 question-answer evidence pairs) by physicians. The questions are manually created using the clinical referral section of the reports that take into account the actual information needs of ordering physicians and eliminate bias from seeing the answer context (and, further, organically create unanswerable questions). The answer spans are marked within the Findings and Impressions sections of a report.", "authors": null}, {"title": "Toward expert-level medical question answering with large language models", "url": "https://www.nature.com/articles/s41591-024-03423-7", "source": "curated", "type": "paper", "date": null, "summary": null, "authors": null}, {"title": "The power of prompting", "url": "https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/", "source": "curated", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review - ACL Anthology", "url": "https://aclanthology.org/2025.acl-long.45/", "type": "paper", "source": "chrome", "date": "2025-01-01", "summary": "Clinical coding is crucial for healthcare billing and data analysis. Manual clinical coding is labour-intensive and error-prone, which has motivated research towards full automation of the process. However, our analysis, based on US English electronic health records and automated coding research using these records, shows that widely used evaluation methods are not aligned with real clinical contexts.", "authors": null}, {"title": "Less is More: Explainable and Efficient ICD Code Prediction with Clinical Entities - ACL Anthology", "url": "https://aclanthology.org/2025.acl-long.1489/", "type": "paper", "source": "chrome", "date": "2025-01-01", "summary": "Clinical coding, assigning standardized codes to medical notes, is critical for epidemiological research, hospital planning, and reimbursement. Neural coding models generally process entire discharge summaries, which are often lengthy and contain information that is not relevant to coding. We propose an approach that combines Named Entity Recognition (NER) and Assertion Classification (AC) to filter for clinically important content before supervised code prediction.", "authors": null}]}, {"name": "Philosophy Lectures and Podcasts", "items": [{"title": "- YouTube", "url": "https://youtu.be/X7Rb56kZQSk?si=TeWgECqQ-tG1dzpj", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "- YouTube", "url": "https://youtu.be/KY9LwCeP7Ug?si=7BREgAw2NYizueyp", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "- YouTube", "url": "https://youtu.be/qX6NztnPU-4?si=Bo9Cj5YRE1MAMhX7", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "- YouTube", "url": "https://youtu.be/8rf3uqDj00A?si=POHJU0EQUjCoIXuo", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "Ep. 333: Kierkegaard's \"Fear and Trembling\" on Faith (Part One)", "url": "https://open.spotify.com/episode/5ay68vg2EjTPceGG19XOhx?si=lBjFt6FbQua_EKly3VJAwg", "source": "curated", "type": "podcast", "summary": null, "date": null, "authors": null}, {"title": "Wittgenstein ep. 1", "url": "https://open.spotify.com/episode/4wsEROopmkAfIKop6w1Lrd", "source": "curated", "type": "podcast", "summary": null, "date": null, "authors": null}, {"title": "Wendell Berry and Ellen Davis — The Art of Being Creatures", "url": "https://open.spotify.com/episode/0xh5CzXIPxAMQzWZWSzYrP?si=74570a0b47f6430e", "source": "curated", "type": "podcast", "summary": null, "date": null, "authors": null}, {"title": "Ram Dass Be You Now: The Lost Talks", "url": "https://open.spotify.com/show/5VpmN5fACJTYlU9DBmBhq9?si=15e815a98f184ab6", "source": "curated", "type": "podcast", "summary": null, "date": null, "authors": null}, {"title": "The Human Condition: Hannah Arendt", "url": "https://open.spotify.com/show/5qxE3BBVIP3DQrmno5dyaL?si=bfa79d329c6e4e4b", "source": "curated", "type": "podcast", "summary": null, "date": null, "authors": null}, {"title": "The Trajectory - What should be the trajectory of intelligence?", "url": "https://open.spotify.com/show/7tELJMkUm6VMiI3Iuoov7S?si=1318fa05be7e408b", "source": "curated", "type": "podcast", "summary": null, "date": null, "authors": null}, {"title": "The Gun Has No Trigger: David Graeber", "url": "https://www.youtube.com/watch?v=h4fQEn15NgI", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "hwcdn.libsyn.com/p/5/7/7/5771ba504306ff28/NWS_Ep.043_Graham_Harman.mp3?c_id=21107832&cs_id=21107832&destination_id=410104&expiration=1534788799&hwt=c79f231b255f17775452af1446d54de4", "url": "http://hwcdn.libsyn.com/p/5/7/7/5771ba504306ff28/NWS_Ep.043_Graham_Harman.mp3?c_id=21107832&cs_id=21107832&destination_id=410104&expiration=1534788799&hwt=c79f231b255f17775452af1446d54de4", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Ep. 043 _ Graham Harman _ 'OOO' - Night White Skies (podcast)", "url": "https://player.fm/series/night-white-skies/ep-043-graham-harman-ooo", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}]}, {"name": "Poems", "items": [{"title": "“Kansas, 4 A.M.”", "url": "https://www.newyorker.com/magazine/2023/04/17/kansas-4-am-kim-addonizio-poem", "source": "curated", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "As I Ebb’d with the Ocean of Life", "url": "https://www.poetryfoundation.org/poems/51003/as-i-ebbd-with-the-ocean-of-life", "source": "curated", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "End of Summer by Louise Glück", "url": "https://www.theguardian.com/books/2003/sep/06/featuresreviews.guardianreview36", "source": "curated", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Song of the Open Road, 15 by Walt Whitman - Poems | Academy of American Poets", "url": "https://poets.org/poem/song-open-road-15", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "POEM: Two Tramps In Mud Time", "url": "https://www.google.com/amp/s/m.poemhunter.com/poem-amp/two-tramps-in-mud-time/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}]}, {"name": "RL for LLMs", "items": [{"title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters", "url": "https://arxiv.org/abs/2408.03314", "source": "both", "type": "paper", "summary": "Enabling LLMs to improve their outputs by using more test-time computation is a critical step towards building generally self-improving agents that can operate on open-ended natural language. In this paper, we study the scaling of inference-time computation in LLMs, with a focus on answering the question: if an LLM is allowed to use a fixed but non-trivial amount of inference-time compute, how much can it improve its performance on a challenging prompt? Answering this question has implications not only on the achievable performance of LLMs, but also on the future of LLM pretraining and how one should tradeoff inference-time and pre-training compute.", "date": "2024-08-06", "authors": ["Charlie Snell", "Jaehoon Lee", "Kelvin Xu", "Aviral Kumar"]}, {"title": "DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models (Paper Explained)", "url": "https://www.youtube.com/watch?v=bAWV_yrqx4w", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "Fin-R1: A Large Language Model for Financial Reasoning through Reinforcement Learning", "url": "https://arxiv.org/abs/2503.16252", "source": "both", "type": "paper", "summary": "In recent years, general-purpose large language models (LLMs) such as GPT, Gemini, Claude, and DeepSeek have advanced at an unprecedented pace. Despite these achievements, their application to finance remains challenging, due to fragmented data sources, intransparent reasoning processes, and weak transferability to business applications. In response, we introduce Fin-R1, a reasoning LLM designed for financial scenarios.", "date": "2025-03-20", "authors": ["Zhaowei Liu", "Xin Guo", "Zhi Yang", "Fangqi Lou", "Lingfeng Zeng", "Mengping Li", "Qi Qi", "Zhiqiang Liu", "Yiyang Han", "Dongpo Cheng", "Ronghao Chen", "Huacan Wang", "Xingdong Feng", "Huixia Judy Wang", "Chengchun Shi", "Liwen Zhang"]}, {"title": "Generative Verifiers: Reward Modeling as Next-Token Prediction", "url": "https://arxiv.org/pdf/2408.15240v1", "source": "curated", "type": "paper", "summary": "Verifiers or reward models are often used to enhance the reasoning performance of large language models (LLMs). A common approach is the Best-of-N method, where N candidate solutions generated by the LLM are ranked by a verifier, and the best one is selected. While LLM-based verifiers are typically trained as discriminative classifiers to score solutions, they do not utilize the text generation capabilities of pretrained LLMs.", "date": "2024-08-27", "authors": ["Lunjun Zhang", "Arian Hosseini", "Hritik Bansal", "Mehran Kazemi", "Aviral Kumar", "Rishabh Agarwal"]}, {"title": "The State of Reinforcement Learning for LLM Reasoning", "url": "https://sebastianraschka.com/blog/2025/the-state-of-reinforcement-learning-for-llm-reasoning.html", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Process Reward Models", "url": "https://www.stephendiehl.com/posts/process_reward/", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "deepseek-ai/DeepSeek-R1 · Hugging Face", "url": "https://huggingface.co/deepseek-ai/DeepSeek-R1", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[2501.12948] DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "url": "https://arxiv.org/abs/2501.12948", "type": "paper", "source": "chrome", "summary": "General reasoning represents a long-standing and formidable challenge in artificial intelligence. Recent breakthroughs, exemplified by large language models (LLMs) and chain-of-thought prompting, have achieved considerable success on foundational reasoning tasks. However, this success is heavily contingent upon extensive human-annotated demonstrations, and models' capabilities are still insufficient for more complex problems.", "date": "2025-01-22", "authors": ["DeepSeek-AI", "Daya Guo", "Dejian Yang", "Haowei Zhang", "Junxiao Song", "Peiyi Wang", "Qihao Zhu", "Runxin Xu", "Ruoyu Zhang", "Shirong Ma", "Xiao Bi", "Xiaokang Zhang", "Xingkai Yu", "Yu Wu", "Z. F. Wu", "Zhibin Gou", "Zhihong Shao", "Zhuoshu Li", "Ziyi Gao", "Aixin Liu", "Bing Xue", "Bingxuan Wang", "Bochao Wu", "Bei Feng", "Chengda Lu", "Chenggang Zhao", "Chengqi Deng", "Chenyu Zhang", "Chong Ruan", "Damai Dai", "Deli Chen", "Dongjie Ji", "Erhang Li", "Fangyun Lin", "Fucong Dai", "Fuli Luo", "Guangbo Hao", "Guanting Chen", "Guowei Li", "H. Zhang", "Han Bao", "Hanwei Xu", "Haocheng Wang", "Honghui Ding", "Huajian Xin", "Huazuo Gao", "Hui Qu", "Hui Li", "Jianzhong Guo", "Jiashi Li", "Jiawei Wang", "Jingchang Chen", "Jingyang Yuan", "Junjie Qiu", "Junlong Li", "J. L. Cai", "Jiaqi Ni", "Jian Liang", "Jin Chen", "Kai Dong", "Kai Hu", "Kaige Gao", "Kang Guan", "Kexin Huang", "Kuai Yu", "Lean Wang", "Lecong Zhang", "Liang Zhao", "Litong Wang", "Liyue Zhang", "Lei Xu", "Leyi Xia", "Mingchuan Zhang", "Minghua Zhang", "Minghui Tang", "Meng Li", "Miaojun Wang", "Mingming Li", "Ning Tian", "Panpan Huang", "Peng Zhang", "Qiancheng Wang", "Qinyu Chen", "Qiushi Du", "Ruiqi Ge", "Ruisong Zhang", "Ruizhe Pan", "Runji Wang", "R. J. Chen", "R. L. Jin", "Ruyi Chen", "Shanghao Lu", "Shangyan Zhou", "Shanhuang Chen", "Shengfeng Ye", "Shiyu Wang", "Shuiping Yu", "Shunfeng Zhou", "Shuting Pan", "S. S. Li", "Shuang Zhou", "Shaoqing Wu", "Shengfeng Ye", "Tao Yun", "Tian Pei", "Tianyu Sun", "T. Wang", "Wangding Zeng", "Wanjia Zhao", "Wen Liu", "Wenfeng Liang", "Wenjun Gao", "Wenqin Yu", "Wentao Zhang", "W. L. Xiao", "Wei An", "Xiaodong Liu", "Xiaohan Wang", "Xiaokang Chen", "Xiaotao Nie", "Xin Cheng", "Xin Liu", "Xin Xie", "Xingchao Liu", "Xinyu Yang", "Xinyuan Li", "Xuecheng Su", "Xuheng Lin", "X. Q. Li", "Xiangyue Jin", "Xiaojin Shen", "Xiaosha Chen", "Xiaowen Sun", "Xiaoxiang Wang", "Xinnan Song", "Xinyi Zhou", "Xianzu Wang", "Xinxia Shan", "Y. K. Li", "Y. Q. Wang", "Y. X. Wei", "Yang Zhang", "Yanhong Xu", "Yao Li", "Yao Zhao", "Yaofeng Sun", "Yaohui Wang", "Yi Yu", "Yichao Zhang", "Yifan Shi", "Yiliang Xiong", "Ying He", "Yishi Piao", "Yisong Wang", "Yixuan Tan", "Yiyang Ma", "Yiyuan Liu", "Yongqiang Guo", "Yuan Ou", "Yuduan Wang", "Yue Gong", "Yuheng Zou", "Yujia He", "Yunfan Xiong", "Yuxiang Luo", "Yuxiang You", "Yuxuan Liu", "Yuyang Zhou", "Y. X. Zhu", "Yanhong Xu", "Yanping Huang", "Yaohui Li", "Yi Zheng", "Yuchen Zhu", "Yunxian Ma", "Ying Tang", "Yukun Zha", "Yuting Yan", "Z. Z. Ren", "Zehui Ren", "Zhangli Sha", "Zhe Fu", "Zhean Xu", "Zhenda Xie", "Zhengyan Zhang", "Zhewen Hao", "Zhicheng Ma", "Zhigang Yan", "Zhiyu Wu", "Zihui Gu", "Zijia Zhu", "Zijun Liu", "Zilin Li", "Ziwei Xie", "Ziyang Song", "Zizheng Pan", "Zhen Huang", "Zhipeng Xu", "Zhongyu Zhang", "Zhen Zhang"]}, {"title": "deepseek_r1 - Google Slides", "url": "https://docs.google.com/presentation/d/1crcUqkvcICmzZFakXhTsHTHJ-_cTHe_PEYpKtXYFD3Q/edit#slide=id.g33366bba500_0_582", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[2501.17161] SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training", "url": "https://arxiv.org/abs/2501.17161", "type": "paper", "source": "chrome", "summary": "Supervised fine-tuning (SFT) and reinforcement learning (RL) are widely used post-training techniques for foundation models. However, their roles in enhancing model generalization capabilities remain unclear. This paper studies the difference between SFT and RL on generalization and memorization, focusing on text-based rule variants and visual variants.", "date": "2025-01-28", "authors": ["Tianzhe Chu", "Yuexiang Zhai", "Jihan Yang", "Shengbang Tong", "Saining Xie", "Dale Schuurmans", "Quoc V. Le", "Sergey Levine", "Yi Ma"]}]}, {"name": "Robust Model Evaluation", "items": [{"title": "A statistical approach to model evaluations", "url": "https://www.anthropic.com/research/statistical-approach-to-model-evals", "source": "both", "type": "blog", "summary": null, "date": null, "authors": null}, {"title": "Precision/Recall on Imbalanced Test Data", "url": "https://proceedings.mlr.press/v206/shang23a.html", "source": "both", "type": "paper", "date": null, "summary": null, "authors": null}, {"title": "11.2 McNemar's Test for Pairwise Classifier Comparison (L11 Model Eval. Part 4)", "url": "https://www.youtube.com/watch?v=nzznkiW8ulk", "source": "curated", "type": "video", "summary": null, "date": null, "authors": null}, {"title": "Pretraining on the Test Set Is All You Need", "url": "https://arxiv.org/abs/2309.08632", "source": "both", "type": "paper", "summary": "Inspired by recent work demonstrating the promise of smaller Transformer-based language models pretrained on carefully curated data, we supercharge such approaches by investing heavily in curating a novel, high quality, non-synthetic data mixture based solely on evaluation benchmarks. Using our novel dataset mixture consisting of less than 100 thousand tokens, we pretrain a 1 million parameter transformer-based LLM \\textbf{phi-CTNL} (pronounced ``fictional\") that achieves perfect results across diverse academic benchmarks, strictly outperforming all known foundation models. \\textbf{phi-CTNL} also beats power-law scaling and exhibits a never-before-seen grokking-like ability to accurately predict downstream evaluation benchmarks' canaries.", "date": "2023-09-13", "authors": ["Rylan Schaeffer"]}, {"title": "McNemar's test - Wikipedia", "url": "https://en.wikipedia.org/wiki/McNemar%27s_test", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Error-Sensitive Evaluation for Ordinal Target Variables - ACL Anthology", "url": "https://aclanthology.org/2021.eval4nlp-1.19/", "type": "paper", "source": "chrome", "date": "2021-01-01", "summary": "Product reviews and satisfaction surveys seek customer feedback in the form of ranked scales. In these settings, widely used evaluation metrics including F1 and accuracy ignore the rank in the responses (e.g., ‘very likely’ is closer to ‘likely’ than ‘not at all’). In this paper, we hypothesize that the order of class values is important for evaluating classifiers on ordinal target variables and should not be disregarded.", "authors": null}]}, {"name": "AI Agents and Agentic Systems", "items": [{"title": "STORM", "url": "https://storm.genie.stanford.edu/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "FutureHouse", "url": "https://www.futurehouse.org/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Exa Websets", "url": "https://websets.exa.ai/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Tiny Agents in Python: a MCP-powered agent in ~70 lines of code", "url": "https://huggingface.co/blog/python-tiny-agents", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Agent Development Kit", "url": "https://google.github.io/adk-docs/", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Agent Development Kit", "url": "https://google.github.io/adk-docs/#what-is-agent-development-kit", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Effective context engineering for AI agents \\ Anthropic", "url": "https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}]}, {"name": "Personal Finance and Economics", "items": [{"title": "Planning and Advice Offerings from Fidelity", "url": "https://www.fidelity.com/bin-public/060_www_fidelity_com/documents/applications/Fidelity_Offerings.pdf", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Voya 401k Dashboard", "url": "https://my.voya.com/myvoyageui/#/workplace-dashboard", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Wall Street is worried stocks might be on the cusp of a ‘lost decade’ - MarketWatch", "url": "https://www.marketwatch.com/story/wall-street-is-worried-stocks-might-be-on-the-cusp-of-a-lost-decade-1b3e2512", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "UBS Wealth Management", "url": "https://onlineservices.ubs.com/wma", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Is a Lost Decade Ahead for Stocks? | Kiplinger", "url": "https://www.kiplinger.com/investing/decade-ahead-stock-expectations#:~:text=%E2%80%9CA%20looming%20lost%20decade%20for,lead%20to%20the%20Roaring%202030s.%E2%80%9D", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "The Daily Shot – Global Macro Currents Visualized.", "url": "https://thedailyshot.com/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}]}, {"name": "Politics and Current Events", "items": [{"title": "Matt Bruenig Dot Com", "url": "https://mattbruenig.com/", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Can illegal immigrants really vote in the US election?", "url": "https://www.bbc.com/news/articles/c5yj98grr5lo", "type": "news", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "How many migrants have crossed the US border illegally?", "url": "https://www.bbc.com/news/articles/c0jp4xqx2z3o", "type": "news", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Tax revenue could drop by 10 percent amid turmoil at IRS - The Washington Post", "url": "https://www.washingtonpost.com/business/2025/03/22/irs-tax-revenue-loss-federal-budget/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Belarus: After five years in jail, opposition figure Tikhanovsky speaks out", "url": "https://www.bbc.com/news/articles/czey1y6x6zzo", "type": "news", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Iowa City community protests ICE after Minneapolis shootings of Renee Good and Alex Pretti - The Daily Iowan", "url": "https://dailyiowan.com/2026/01/25/iowa-city-community-protests-ice-after-minneapolis-shootings-of-renee-good-and-alex-pretti/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}]}, {"name": "Statistics and Data Science Methodology", "items": [{"title": "Margin of Error Guide & Calculator - Qualtrics", "url": "https://www.qualtrics.com/experience-management/research/margin-of-error/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "regression - Why does sklearn Ridge not accept warm start? - Cross Validated", "url": "https://stats.stackexchange.com/questions/343659/why-does-sklearn-ridge-not-accept-warm-start", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Permutation test - Wikipedia", "url": "https://en.wikipedia.org/wiki/Permutation_test", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Kemeny method - Wikipedia", "url": "https://en.wikipedia.org/wiki/Kemeny_method", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "neural networks - What exactly are keys, queries, and values in attention mechanisms? - Cross Validated", "url": "https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Statistical forecasting: notes on regression and time series analysis", "url": "http://people.duke.edu/~rnau/411home.htm", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}]}, {"name": "Essays, Writing, and Ideas", "items": [{"title": "Generative AI Might Finally Bend Copyright Past the Breaking Point - The Atlantic", "url": "https://www.theatlantic.com/technology/archive/2024/02/generative-ai-lawsuits-copyright-fair-use/677595/?utm_source=msn", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "In Praise of Search Tools - Public Books", "url": "https://www.publicbooks.org/in-praise-of-search-tools/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "How creativity became the reigning value of our time | MIT Technology Review", "url": "https://www.technologyreview.com/2025/04/18/1114478/cult-of-creativity-samuel-franklin-book-technology-ai/#amp_tf=From%20%251%24s&aoh=17453336318080&csi=0&referrer=https%3A%2F%2Fwww.google.com&share=https%3A%2F%2Fwww.technologyreview.com%2F2025%2F04%2F18%2F1114478%2Fcult-of-creativity-samuel-franklin-book-technology-ai%2F", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Writes and Write-Nots", "url": "https://www.paulgraham.com/writes.html", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "I love AI. Why doesn't everyone? - by Noah Smith", "url": "https://www.noahpinion.blog/p/i-love-ai-why-doesnt-everyone", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "[2507.23242] Annotation-Free Reinforcement Learning Query Rewriting via Verifiable Search Reward", "url": "https://arxiv.org/abs/2507.23242", "type": "paper", "source": "chrome", "summary": "Optimizing queries for Retrieval-Augmented Generation (RAG) systems poses a significant challenge, particularly across diverse modal indices. We introduce RL-QR, a novel annotation-free reinforcement learning framework for query rewriting that eliminates the need for costly human-annotated data. By leveraging verifiable search rewards derived from index-aligned synthetic queries, RL-QR overcomes human-annotation dependencies, extending its applicability to various modalities and index domains.", "date": "2025-07-31", "authors": ["Sungguk Cha", "DongWook Kim", "Taeseung Hahn", "Mintae Kim", "Youngsub Han", "Byoung-Ki Jeon"]}, {"title": "Edward Feser: David Foster Wallace on abstraction", "url": "http://edwardfeser.blogspot.com/2018/01/david-foster-wallace-on-abstraction.html?m=1", "type": "blog", "source": "chrome", "summary": null, "date": null, "authors": null}]}, {"name": "Career and Professional Development", "items": [{"title": "How highly successful people talk to their bosses: It’ll give you ‘a competitive edge’", "url": "https://www.cnbc.com/2025/09/30/how-highly-successful-people-talk-to-their-bosses-it-will-give-you-a-competitive-edge.html#amp_tf=From%20%251%24s&aoh=17593746272155&csi=0&referrer=https%3A%2F%2Fwww.google.com&share=https%3A%2F%2Fwww.cnbc.com%2F2025%2F09%2F30%2Fhow-highly-successful-people-talk-to-their-bosses-it-will-give-you-a-competitive-edge.html", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "What Is a Principal Data Scientist? A Deep Dive Into What the Role Actually Requires - Versifai Blog", "url": "https://www.versifai.org/blog/what-is-a-principal-data-scientist", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}]}, {"name": "Miscellaneous", "items": [{"title": "Iris Intern Prep Notes - Google Docs", "url": "https://docs.google.com/document/d/1qL8m3DWD6O9nXUQbPWwr7M2rNas5rf9DeexChMOY-6M/edit?tab=t.0", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Google caters to the DIY crowd with an AI camera kit for Raspberry Pi", "url": "https://www.google.com/amp/s/www.engadget.com/amp/2017/11/30/google-diy-ai-camera-kit-raspberry-pi/", "type": "other", "source": "chrome", "summary": null, "date": null, "authors": null}, {"title": "Creating An HTML5 Game Bot Using Python | vesche", "url": "http://vesche.github.io/articles/01-stabbybot.html", "type": "repo", "source": "chrome", "summary": null, "date": null, "authors": null}]}]};

const TYPES = ["paper","repo","blog","video","tool","podcast","documentation","news","other"];
const activeTypes = new Set();

// --- Pending additions from localStorage ---
function getPending() {
  try { return JSON.parse(localStorage.getItem("kb_pending_additions") || "[]"); }
  catch { return []; }
}
function savePending(arr) {
  localStorage.setItem("kb_pending_additions", JSON.stringify(arr));
}
function getMergedData() {
  const pending = getPending();
  if (pending.length === 0) return DATA;
  const merged = JSON.parse(JSON.stringify(DATA));
  pending.forEach(p => {
    const cat = merged.categories.find(c => c.name === p._category);
    if (cat) {
      const item = {...p};
      delete item._category;
      cat.items.push(item);
    }
  });
  merged.metadata.total_items = 0;
  merged.categories.forEach(c => merged.metadata.total_items += c.items.length);
  return merged;
}

function getDomain(url) {
  try { return new URL(url).hostname.replace("www.", ""); } catch { return ""; }
}

function formatAuthors(authors) {
  if (!authors || authors.length === 0) return "";
  if (authors.length <= 3) return authors.join(", ");
  return authors[0] + " et al.";
}

function isEnriched(item) {
  return item.summary != null && item.summary !== "";
}

function formatYear(date) {
  if (!date) return null;
  return date.substring(0, 4);
}

function escapeHtml(str) {
  const div = document.createElement("div");
  div.textContent = str;
  return div.innerHTML;
}

function render() {
  const container = document.getElementById("container");
  const noResults = document.getElementById("no-results");
  container.innerHTML = "";
  container.appendChild(noResults);

  const merged = getMergedData();
  const pending = getPending();
  const pendingUrls = new Set(pending.map(p => p.url));

  // Populate category dropdown
  const catSelect = document.getElementById("bm-category");
  catSelect.innerHTML = "";
  merged.categories.forEach(cat => {
    const opt = document.createElement("option");
    opt.value = cat.name;
    opt.textContent = cat.name;
    catSelect.appendChild(opt);
  });

  merged.categories.forEach((cat, ci) => {
    const div = document.createElement("div");
    div.className = "category open";
    div.dataset.index = ci;

    const header = document.createElement("div");
    header.className = "cat-header";
    header.innerHTML = `
      <span class="cat-title">${escapeHtml(cat.name)} <span class="cat-count">${cat.items.length}</span></span>
      <span class="chevron">&#9654;</span>
    `;
    header.addEventListener("click", () => div.classList.toggle("open"));

    const itemsDiv = document.createElement("div");
    itemsDiv.className = "cat-items";

    cat.items.forEach((item, ii) => {
      const row = document.createElement("div");
      row.className = "item-row";
      row.dataset.cat = ci;
      row.dataset.item = ii;
      row.dataset.type = item.type;

      const searchParts = [item.title, item.url, cat.name];
      if (item.summary) searchParts.push(item.summary);
      if (item.authors) searchParts.push(item.authors.join(" "));
      row.dataset.search = searchParts.join(" ").toLowerCase();

      const enriched = isEnriched(item);
      const domain = getDomain(item.url);
      const year = formatYear(item.date);
      const authorsStr = formatAuthors(item.authors);
      const isPending = pendingUrls.has(item.url);

      // Main row
      const mainDiv = document.createElement("div");
      mainDiv.className = "item";

      let dotClass = enriched ? "filled" : "empty";
      let dotHtml = `<span class="enrichment-dot ${dotClass}"></span>`;
      let badgeHtml = `<span class="type-badge type-${item.type}">${escapeHtml(item.type)}</span>`;
      let yearHtml = year ? `<span class="date-badge">${year}</span>` : "";
      let linkHtml = `<a class="item-link" href="${escapeHtml(item.url)}" target="_blank" rel="noopener" onclick="event.stopPropagation()">${escapeHtml(item.title)}</a>`;
      let authorsHtml = authorsStr ? `<span class="authors-inline">${escapeHtml(authorsStr)}</span>` : "";
      let pendingHtml = isPending ? `<span class="pending-badge">pending</span>` : "";
      let domainHtml = `<span class="item-domain">${escapeHtml(domain)}</span>`;

      mainDiv.innerHTML = dotHtml + badgeHtml + linkHtml + yearHtml + authorsHtml + pendingHtml + domainHtml;

      // Click row to expand detail (not the link)
      mainDiv.addEventListener("click", (e) => {
        if (e.target.tagName === "A") return;
        row.classList.toggle("expanded");
      });

      // Detail panel
      const detailDiv = document.createElement("div");
      detailDiv.className = "item-detail";
      if (item.summary) {
        detailDiv.innerHTML += `<div class="detail-summary">${escapeHtml(item.summary)}</div>`;
      }
      if (item.authors && item.authors.length > 0) {
        detailDiv.innerHTML += `<div class="detail-authors">${escapeHtml(item.authors.join(", "))}</div>`;
      }
      if (item.date) {
        detailDiv.innerHTML += `<div style="margin-top:2px">Published: ${escapeHtml(item.date)}</div>`;
      }
      if (!item.summary && !item.authors && !item.date) {
        detailDiv.innerHTML = `<div style="color:var(--text2);font-style:italic">No enriched metadata available.</div>`;
      }

      row.appendChild(mainDiv);
      row.appendChild(detailDiv);
      itemsDiv.appendChild(row);
    });

    div.appendChild(header);
    div.appendChild(itemsDiv);
    container.appendChild(div);
  });

  updatePendingCount();
  updateStats();
}

function applyFilters() {
  const q = document.getElementById("search").value.toLowerCase().trim();
  const tokens = q.split(/\s+/).filter(Boolean);
  const filterByType = activeTypes.size > 0;

  let totalVisible = 0;

  document.querySelectorAll(".category").forEach(cat => {
    const items = cat.querySelectorAll(".item-row");
    let catVisible = 0;

    items.forEach(item => {
      const matchType = !filterByType || activeTypes.has(item.dataset.type);
      const searchStr = item.dataset.search;
      const matchSearch = tokens.length === 0 || tokens.every(t => searchStr.includes(t));

      if (matchType && matchSearch) {
        item.classList.remove("hidden");
        catVisible++;
      } else {
        item.classList.add("hidden");
      }
    });

    if (catVisible === 0) {
      cat.classList.add("hidden");
    } else {
      cat.classList.remove("hidden");
      cat.classList.add("open");
      cat.querySelector(".cat-count").textContent = catVisible;
    }
    totalVisible += catVisible;
  });

  document.getElementById("no-results").style.display = totalVisible === 0 ? "block" : "none";
  updateStats(totalVisible);
}

function updateStats(visible) {
  const total = getMergedData().metadata.total_items;
  if (visible === undefined || visible === total) {
    document.getElementById("stats").textContent = total + " items";
  } else {
    document.getElementById("stats").textContent = visible + " / " + total + " items";
  }
}

function updatePendingCount() {
  const pending = getPending();
  const el = document.getElementById("bm-pending-count");
  el.textContent = pending.length > 0 ? pending.length + " pending" : "";
}

function renderFilters() {
  const bar = document.getElementById("filters");
  TYPES.forEach(type => {
    const btn = document.createElement("button");
    btn.className = "filter-btn";
    btn.textContent = type;
    btn.addEventListener("click", () => {
      if (activeTypes.has(type)) {
        activeTypes.delete(type);
        btn.classList.remove("active");
      } else {
        activeTypes.add(type);
        btn.classList.add("active");
      }
      applyFilters();
    });
    bar.appendChild(btn);
  });
}

// --- Bookmark panel ---
document.getElementById("bookmark-toggle").addEventListener("click", () => {
  const panel = document.getElementById("bookmark-panel");
  const toggle = document.getElementById("bookmark-toggle");
  panel.classList.toggle("open");
  toggle.classList.toggle("active");
});

document.getElementById("bm-add").addEventListener("click", () => {
  const url = document.getElementById("bm-url").value.trim();
  const title = document.getElementById("bm-title").value.trim();
  const category = document.getElementById("bm-category").value;
  const type = document.getElementById("bm-type").value;
  const summary = document.getElementById("bm-summary").value.trim() || null;

  if (!url) { alert("URL is required."); return; }
  if (!title) { alert("Title is required."); return; }

  const pending = getPending();
  pending.push({
    title: title,
    url: url,
    type: type,
    source: "user",
    summary: summary,
    date: null,
    authors: null,
    _category: category
  });
  savePending(pending);

  // Clear form
  document.getElementById("bm-url").value = "";
  document.getElementById("bm-title").value = "";
  document.getElementById("bm-summary").value = "";

  render();
  applyFilters();
});

document.getElementById("bm-export").addEventListener("click", () => {
  const merged = getMergedData();
  const blob = new Blob([JSON.stringify(merged, null, 2)], {type: "application/json"});
  const a = document.createElement("a");
  a.href = URL.createObjectURL(blob);
  a.download = "joel_stremmel_knowledge_base.json";
  a.click();
  URL.revokeObjectURL(a.href);
});

// --- Auto-populate title from URL ---
document.getElementById("bm-url").addEventListener("blur", async () => {
  const url = document.getElementById("bm-url").value.trim();
  const titleField = document.getElementById("bm-title");
  if (url && !titleField.value.trim()) {
    // Try to guess title from URL path
    try {
      const u = new URL(url);
      const pathParts = u.pathname.split("/").filter(Boolean);
      if (pathParts.length > 0) {
        const last = decodeURIComponent(pathParts[pathParts.length - 1])
          .replace(/[-_]/g, " ")
          .replace(/\.[^.]+$/, "");
        titleField.value = last;
      }
    } catch {}
  }
});

// --- Keyboard shortcuts ---
document.getElementById("search").addEventListener("input", applyFilters);

document.addEventListener("keydown", e => {
  if (e.key === "/" && document.activeElement.tagName !== "INPUT" && document.activeElement.tagName !== "TEXTAREA") {
    e.preventDefault();
    document.getElementById("search").focus();
  }
  if (e.key === "Escape") {
    const search = document.getElementById("search");
    search.value = "";
    search.blur();
    activeTypes.clear();
    document.querySelectorAll(".filter-btn").forEach(b => b.classList.remove("active"));
    applyFilters();
  }
  if ((e.key === "e" || e.key === "E") && document.activeElement.tagName !== "INPUT" && document.activeElement.tagName !== "TEXTAREA") {
    document.querySelectorAll(".category").forEach(c => c.classList.add("open"));
  }
  if ((e.key === "c" || e.key === "C") && document.activeElement.tagName !== "INPUT" && document.activeElement.tagName !== "TEXTAREA") {
    document.querySelectorAll(".category").forEach(c => c.classList.remove("open"));
  }
});

render();
renderFilters();
</script>
</body>
</html>